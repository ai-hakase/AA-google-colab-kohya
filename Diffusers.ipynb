{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diffusers ライブラリを用いて、画像を生成するスクリプト。**"
      ],
      "metadata": {
        "id": "FDWXJo4TqbdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWp1KnOyYgD8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title Driveに接続 { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JE2OGdlsZZ4W"
      },
      "outputs": [],
      "source": [
        "#@title ライブラリの追加, LoRAの読み込み { display-mode: \"form\" }\n",
        "\n",
        "# !pip install diffusers==0.12.1\n",
        "# diffusers[torch] 以外の のインストール\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "\n",
        "def load_safetensors_lora(pipeline, checkpoint_path, LORA_PREFIX_UNET=\"lora_unet\", LORA_PREFIX_TEXT_ENCODER=\"lora_te\", alpha=0.75):\n",
        "    # load LoRA weight from .safetensors\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "\n",
        "    visited = []\n",
        "\n",
        "    # directly update weight in diffusers model\n",
        "    for key in state_dict:\n",
        "        # it is suggested to print out the key, it usually will be something like below\n",
        "        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\n",
        "\n",
        "        # as we have set the alpha beforehand, so just skip\n",
        "        if \".alpha\" in key or key in visited:\n",
        "            continue\n",
        "\n",
        "        if \"text\" in key:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_TEXT_ENCODER + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.text_encoder\n",
        "        else:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_UNET + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.unet\n",
        "\n",
        "        # find the target layer\n",
        "        temp_name = layer_infos.pop(0)\n",
        "        while len(layer_infos) > -1:\n",
        "            try:\n",
        "                curr_layer = curr_layer.__getattr__(temp_name)\n",
        "                if len(layer_infos) > 0:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "                elif len(layer_infos) == 0:\n",
        "                    break\n",
        "            except Exception:\n",
        "                if len(temp_name) > 0:\n",
        "                    temp_name += \"_\" + layer_infos.pop(0)\n",
        "                else:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "\n",
        "        pair_keys = []\n",
        "        if \"lora_down\" in key:\n",
        "            pair_keys.append(key.replace(\"lora_down\", \"lora_up\"))\n",
        "            pair_keys.append(key)\n",
        "        else:\n",
        "            pair_keys.append(key)\n",
        "            pair_keys.append(key.replace(\"lora_up\", \"lora_down\"))\n",
        "\n",
        "        # update weight\n",
        "        if len(state_dict[pair_keys[0]].shape) == 4:\n",
        "            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n",
        "        else:\n",
        "            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n",
        "\n",
        "        # update visited list\n",
        "        for item in pair_keys:\n",
        "            visited.append(item)\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WbyLfEFDYlcA",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edf1708-45f3-4136-f7e8-627d73a3d861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "safety_checker/model.safetensors not found\n"
          ]
        }
      ],
      "source": [
        "#@title LoRAを設定 　★ memo:　majicMIX_realistic_v6（アジア美女：リアル）,　stable-diffusion-v1-5（猫：リアル） { display-mode: \"form\" }\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "\n",
        "#画像生成に使うモデルデータ\n",
        "model_id = \"emilianJR/majicMIX_realistic_v6\" #@param [\"runwayml/stable-diffusion-v1-5\", \"emilianJR/majicMIX_realistic_v6\"]\n",
        "#画像生成に使うVAE\n",
        "vae_id = \"stabilityai/sd-vae-ft-mse\" #@param {type:\"string\"}\n",
        "vae = AutoencoderKL.from_pretrained(vae_id)\n",
        "#画像生成に使うスケジューラー\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "#パイプラインの作成\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, vae=vae, custom_pipeline=\"lpw_stable_diffusion\")\n",
        "\n",
        "# Ture / False\n",
        "\n",
        "#LoRAを読み込む\n",
        "LoRA_USE = False #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/Lora/add_detail.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha = 0.5 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "#LoRA_2を読み込む flat2 -1, LickingOralLoRA 0.5, koreanDollLikeness 0.8, DDpovbj_1ot\n",
        "LoRA_USE_2= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/Lora/flat2.safetensors\" #@param (string)\n",
        "  LoRA_alpha_2 = 0.1 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "#LoRA_3を読み込む\n",
        "LoRA_USE_3= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\" #@param (string)\n",
        "  LoRA_alpha_3 = 0.4 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "#LoRA_4を読み込む\n",
        "LoRA_USE_4= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\" #@param (string)\n",
        "  LoRA_alpha_4 = 0.5 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#NSFW規制を無効化する\n",
        "if pipe.safety_checker is not None:\n",
        "  pipe.safety_checker = lambda images, **kwargs: (images, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3U5yBOIFq9i"
      },
      "outputs": [],
      "source": [
        "#@title 画像を生成とZIPのダウンロード ＋ 終わったフォルダを移動 { display-mode: \"form\" }\n",
        "\n",
        "# 必要なモジュールやライブラリをインポートする\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# txt2img出力画像の保存先（日付ごと）\n",
        "now = datetime.datetime.now()\n",
        "output_dir = f\"/content/drive/MyDrive/txt2img_output-{now.strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマット\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "\n",
        "# ポジティブプロンプト\n",
        "prompt = \"beautiful woman in micro bikini,(masterpiece),((ultra-detailed)),(expressionless),realistic8K UHD,(best quality:1.2), High definition, intricate details, detailed texture, high detail, Detailed beautiful delicate eyes, a face of perfect proportion, Particles of Light, distinct_image, high_resolution,  high quality texture and shadow, a realistic and beautiful face with big eyes, blush, glossy lips and perfect proportion, Depth of field, Lens Flare, Ray tracing,perspective, Prominent Nose, slender face, perfect and lean body,(narrow waist:1.3), medium breast, (lustrous skin), (pureerosface_v1:0.5) , (ulzzang-6500-v1.1:0.5), braun short hair, sitting, (spreading legs:1.5),((Due to the intense physical activity sweat is visible on her body and her clothes are soaked through and transparet, exposed pussy)),(exposed bikini pants:1.35),(camel toes:1.2)BREAK (smiling, embarrassed), nsfw ,in pool,\" # @param {type:\"string\"}\n",
        "\n",
        "# ネガティブプロンプト\n",
        "n_prompt = \"paintings, sketches,(worst quality:2), (low quality:2), (normal quality:2), bad feet, (absurdly large penis,malformed penis:1.2), lowres, ((monochrome)), skin spots, extra penis, acnes, skin blemishes, bad anatomy, bad hands, text, error, missing fingers,extra digit, fewer digits, cropped, worstquality,jpegartifacts,signature, watermark, username,blurry,bad feet,(mutation,deformed:1.3), (absurdly large penis,malformed penis:1.2),extra limbs,fused fingers,long neck,cross-eyed,polar lowres,bad proportions,(ng_deepnegative_v1_75t),(negative_hand-neg)\" # @param {type:\"string\"}\n",
        "\n",
        "# 生成枚数\n",
        "num_images = 3 # @param {type:\"integer\"}\n",
        "\n",
        "# seed値 ex) 11897334222\n",
        "isFixSeed = False # @param {type:\"boolean\"}\n",
        "seed = -1 # @param {type:\"integer\"}\n",
        "\n",
        "# 画像の幅と高さ\n",
        "width = \"1200\" # @param [600, 800, 1200]\n",
        "height = \"800\" # @param [600, 800, 1200, 1600, 1800]\n",
        "\n",
        "# guidance_scaleの値\n",
        "guidance_scale = 8 # @param {type:\"number\"}\n",
        "\n",
        "# num_inference_stepsの値\n",
        "num_inference_steps = 60 # @param {type:\"integer\"}\n",
        "\n",
        "# 画像を生成して保存する関数\n",
        "def generate_and_save_image(prompt, n_prompt, seed):\n",
        "\n",
        "  # isFixSeedとseedの値に応じてgeneratorを作成する\n",
        "  if isFixSeed and seed != -1: # seed固定して同じ画像を生成する場合\n",
        "    generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "  else: # seed=-1（ランダム）の場合\n",
        "    generator = None\n",
        "\n",
        "  image = pipe(prompt, negative_prompt=n_prompt, width=int(width), height=int(height), generator=generator, guidance_scale=guidance_scale, num_inference_steps=num_inference_steps).images[0]\n",
        "\n",
        "  # 出力する画像の名前を生成する\n",
        "  image_name = datetime.datetime.now().strftime(file_format) + \".png\"\n",
        "\n",
        "  # 画像を保存する\n",
        "  save_location = os.path.join(output_dir, image_name)\n",
        "  image.save(save_location)\n",
        "\n",
        "  # 生成した画像の名前と保存先を返す\n",
        "  return image_name, save_location\n",
        "\n",
        "# num_images分だけ画像を生成して保存する\n",
        "image_names = [] # 生成した画像の名前のリスト\n",
        "for i in range(num_images):\n",
        "  image_name, save_location = generate_and_save_image(prompt, n_prompt, seed)\n",
        "  image_names.append(image_name)\n",
        "\n",
        "# ダウンロードが終わったらZipにする。\n",
        "\n",
        "# ファイル名を生成する\n",
        "file_name = output_dir.split(\"/\")[-1]\n",
        "\n",
        "# フォルダをzip圧縮する\n",
        "shutil.make_archive(file_name, 'zip', output_dir)\n",
        "\n",
        "# Zipをダウンロード\n",
        "files.download(f'/content/{file_name}.zip')\n",
        "\n",
        "# 終わったらフォルダ名を変更する\n",
        "# new_file_name = \"ok---\" + file_name # 新しいフォルダ名\n",
        "# os.rename(output_dir, os.path.join(\"/content/drive/MyDrive\", new_file_name)) # フォルダ名を変更する\n",
        "\n",
        "# End-downloadingというフォルダを作る\n",
        "end_downloading_dir = \"/content/drive/MyDrive/End-downloading\"\n",
        "os.makedirs(end_downloading_dir, exist_ok=True)\n",
        "\n",
        "# フォルダ名を変更したフォルダをEnd-downloadingに移動する\n",
        "shutil.move(os.path.join(\"/content/drive/MyDrive\", file_name), end_downloading_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}