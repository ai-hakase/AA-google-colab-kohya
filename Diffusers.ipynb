{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diffusers ライブラリを用いて、画像を生成するスクリプト。**"
      ],
      "metadata": {
        "id": "FDWXJo4TqbdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWp1KnOyYgD8",
        "outputId": "626668aa-b050-4a5a-a597-a54619873d8e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Driveに接続 { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE2OGdlsZZ4W"
      },
      "outputs": [],
      "source": [
        "#@title ライブラリの追加, LoRAの読み込み { display-mode: \"form\" }\n",
        "\n",
        "# !pip install diffusers==0.12.1\n",
        "# diffusers[torch] 以外の のインストール\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors >/dev/null 2>&1\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "\n",
        "def load_safetensors_lora(pipeline, checkpoint_path, LORA_PREFIX_UNET=\"lora_unet\", LORA_PREFIX_TEXT_ENCODER=\"lora_te\", alpha=0.75):\n",
        "    # load LoRA weight from .safetensors\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "\n",
        "    visited = []\n",
        "\n",
        "    # directly update weight in diffusers model\n",
        "    for key in state_dict:\n",
        "        # it is suggested to print out the key, it usually will be something like below\n",
        "        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\n",
        "\n",
        "        # as we have set the alpha beforehand, so just skip\n",
        "        if \".alpha\" in key or key in visited:\n",
        "            continue\n",
        "\n",
        "        if \"text\" in key:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_TEXT_ENCODER + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.text_encoder\n",
        "        else:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_UNET + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.unet\n",
        "\n",
        "        # find the target layer\n",
        "        temp_name = layer_infos.pop(0)\n",
        "        while len(layer_infos) > -1:\n",
        "            try:\n",
        "                curr_layer = curr_layer.__getattr__(temp_name)\n",
        "                if len(layer_infos) > 0:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "                elif len(layer_infos) == 0:\n",
        "                    break\n",
        "            except Exception:\n",
        "                if len(temp_name) > 0:\n",
        "                    temp_name += \"_\" + layer_infos.pop(0)\n",
        "                else:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "\n",
        "        pair_keys = []\n",
        "        if \"lora_down\" in key:\n",
        "            pair_keys.append(key.replace(\"lora_down\", \"lora_up\"))\n",
        "            pair_keys.append(key)\n",
        "        else:\n",
        "            pair_keys.append(key)\n",
        "            pair_keys.append(key.replace(\"lora_up\", \"lora_down\"))\n",
        "\n",
        "        # update weight\n",
        "        if len(state_dict[pair_keys[0]].shape) == 4:\n",
        "            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n",
        "        else:\n",
        "            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n",
        "\n",
        "        # update visited list\n",
        "        for item in pair_keys:\n",
        "            visited.append(item)\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbyLfEFDYlcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c74d7df1-e254-4ee7-d146-7d81bed04002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        }
      ],
      "source": [
        "#@title LoRAを設定 　★ memo:　majicMIX_realistic_v6（アジア美女：リアル）,　stable-diffusion-v1-5（猫：リアル） { display-mode: \"form\" }\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "\n",
        "#画像生成に使うモデルデータ\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\" #@param [\"runwayml/stable-diffusion-v1-5\", \"emilianJR/majicMIX_realistic_v6\"]\n",
        "#画像生成に使うVAE\n",
        "vae_id = \"stabilityai/sd-vae-ft-ema\" #@param {type:\"string\"}\n",
        "vae = AutoencoderKL.from_pretrained(vae_id)\n",
        "#画像生成に使うスケジューラー\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "#パイプラインの作成\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, vae=vae, custom_pipeline=\"lpw_stable_diffusion\")\n",
        "\n",
        "# Ture / False\n",
        "\n",
        "#LoRAを読み込む\n",
        "LoRA_USE = False #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/Lora/add_detail.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha = 0.7 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "#LoRA_2を読み込む flat2 -1, LickingOralLoRA 0.5, koreanDollLikeness 0.8, DDpovbj_1ot\n",
        "LoRA_USE_2= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/Lora/flat2.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha_2 = -1 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "#LoRA_3を読み込む\n",
        "LoRA_USE_3= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha_3 = 0.6 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "#LoRA_4を読み込む\n",
        "LoRA_USE_4= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\" #@param (string)\n",
        "  LoRA_alpha_4 = 0.8 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#NSFW規制を無効化する\n",
        "if pipe.safety_checker is not None:\n",
        "  pipe.safety_checker = lambda images, **kwargs: (images, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3U5yBOIFq9i"
      },
      "outputs": [],
      "source": [
        "#@title 画像を生成 { display-mode: \"form\" }\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# txt2img出力画像の保存先（日付ごと）\n",
        "today = datetime.date.today()\n",
        "output_dir = f\"/content/drive/MyDrive/txt2img_output/{today.strftime('%Y%m%d')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "\n",
        "# ポジティブプロンプト\n",
        "prompt = \"cat , looking at viewer, simple background, no humans, animal, black background, realistic, animal focus, closed mouth, lying, on side, full body, whiskers, yellow eyes, solo, white fur\" #@param {type:\"string\"}\n",
        "\n",
        "# ネガティブプロンプト\n",
        "n_prompt = \"loli, wide hips, thick thighs, sagging breasts, (malformed hands, missing fingers, extra digit, fewer digits, bad hands, poorly drawn hands, poorly drawn fingers, missing fingers:1.8),  (face only,body only,legs only,tail only:1.3), lowres, cropped, (worst quality, low quality:1.4), normal quality, jpeg artifacts, desaturated, greyscale, (panel layout, multiple views, multiple angle, two shot, split view, grid view, out of focus, blurry, bokeh:2.0). (text, error, signature, watermark, username, artist name, logo, name, censored:1.5), fat, ugly, mutation, mutated, deformed, bad anatomy, missing arms, three arms, four arms, poorly drawn face, deformed iris, simple iris, heterochromia, long neck, long body, disfigured, extra limb, missing limb, floating limbs, disconnected limbs, (zombie, sketch, interlocked fingers,comic), nsfw\" #@param {type:\"string\"}\n",
        "\n",
        "# 生成枚数\n",
        "num_images = 3 #@param {type:\"integer\"}\n",
        "\n",
        "# seed値 ex) 11897334222\n",
        "seed = -1 #@param {type:\"integer\"}\n",
        "\n",
        "# 画像を生成して保存する関数\n",
        "def generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format):\n",
        "  # seed固定\n",
        "  # generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "  # image = pipe(prompt, negative_prompt=n_prompt, width=768, height=512, generator=generator, guidance_scale=7, num_inference_steps=20).images[0]\n",
        "\n",
        "  # seed=-1（ランダム）の場合  width=512, height=768, width=768, height=1152\n",
        "  width = 512 # @param [512, 768]\n",
        "  height = 768 # @param [512, 768, 1152]\n",
        "  guidance_scale = 7 #@param {type:\"number\"}\n",
        "  num_inference_steps = 20 #@param {type:\"integer\"}\n",
        "  image = pipe(prompt, negative_prompt=n_prompt, width=width, height=height, guidance_scale=guidance_scale, num_inference_steps=num_inference_steps).images[0]\n",
        "\n",
        "  # 出力する画像の名前を生成する\n",
        "  image_name = datetime.datetime.now().strftime(file_format) + \".png\"\n",
        "\n",
        "  # 画像を保存する\n",
        "  save_location = os.path.join(output_dir, image_name)\n",
        "  image.save(save_location)\n",
        "\n",
        "# num_images分だけ画像を生成して保存する\n",
        "for i in range(num_images):\n",
        "  generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title ランタイムの接続を解除して削除 { display-mode: \"form\" }\n",
        "\n",
        "# # google.colabライブラリのインポート\n",
        "# import google.colab\n",
        "\n",
        "# # ランタイムの接続を解除して削除\n",
        "# google.colab.runtime.unassign()\n"
      ],
      "metadata": {
        "id": "GMsGW-MtjK4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}