{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diffusers ライブラリを用いて、画像を生成するスクリプト。**"
      ],
      "metadata": {
        "id": "FDWXJo4TqbdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWp1KnOyYgD8",
        "outputId": "f0e8c83e-c227-42d9-812d-d5fea76d48c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Driveに接続 { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JE2OGdlsZZ4W"
      },
      "outputs": [],
      "source": [
        "#@title ライブラリの追加, LoRAの読み込み { display-mode: \"form\" }\n",
        "\n",
        "# !pip install diffusers==0.12.1\n",
        "# diffusers[torch] 以外の のインストール\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors >/dev/null 2>&1\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "\n",
        "def load_safetensors_lora(pipeline, checkpoint_path, LORA_PREFIX_UNET=\"lora_unet\", LORA_PREFIX_TEXT_ENCODER=\"lora_te\", alpha=0.75):\n",
        "    # load LoRA weight from .safetensors\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "\n",
        "    visited = []\n",
        "\n",
        "    # directly update weight in diffusers model\n",
        "    for key in state_dict:\n",
        "        # it is suggested to print out the key, it usually will be something like below\n",
        "        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\n",
        "\n",
        "        # as we have set the alpha beforehand, so just skip\n",
        "        if \".alpha\" in key or key in visited:\n",
        "            continue\n",
        "\n",
        "        if \"text\" in key:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_TEXT_ENCODER + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.text_encoder\n",
        "        else:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_UNET + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.unet\n",
        "\n",
        "        # find the target layer\n",
        "        temp_name = layer_infos.pop(0)\n",
        "        while len(layer_infos) > -1:\n",
        "            try:\n",
        "                curr_layer = curr_layer.__getattr__(temp_name)\n",
        "                if len(layer_infos) > 0:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "                elif len(layer_infos) == 0:\n",
        "                    break\n",
        "            except Exception:\n",
        "                if len(temp_name) > 0:\n",
        "                    temp_name += \"_\" + layer_infos.pop(0)\n",
        "                else:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "\n",
        "        pair_keys = []\n",
        "        if \"lora_down\" in key:\n",
        "            pair_keys.append(key.replace(\"lora_down\", \"lora_up\"))\n",
        "            pair_keys.append(key)\n",
        "        else:\n",
        "            pair_keys.append(key)\n",
        "            pair_keys.append(key.replace(\"lora_up\", \"lora_down\"))\n",
        "\n",
        "        # update weight\n",
        "        if len(state_dict[pair_keys[0]].shape) == 4:\n",
        "            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n",
        "        else:\n",
        "            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n",
        "\n",
        "        # update visited list\n",
        "        for item in pair_keys:\n",
        "            visited.append(item)\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "WbyLfEFDYlcA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b9796be3-51b3-4e5f-fb25-7a92ebca6946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 43>\u001b[0m:\u001b[94m46\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mload_safetensors_lora\u001b[0m:\u001b[94m13\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/safetensors/\u001b[0m\u001b[1;33mtorch.py\u001b[0m:\u001b[94m259\u001b[0m in \u001b[92mload_file\u001b[0m                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m```\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   \u001b[0mresult = {}                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m259 \u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m safe_open(filename, framework=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m, device=device) \u001b[94mas\u001b[0m f:                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m f.keys():                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult[k] = f.get_tensor(k)                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m result                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mFileNotFoundError: \u001b[0mNo such file or directory: \u001b[32m\"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 43&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">46</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_safetensors_lora</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/safetensors/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">torch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">259</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_file</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">256 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">```</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">257 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>result = {}                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>259 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> safe_open(filename, framework=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>, device=device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> f:                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> f.keys():                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result[k] = f.get_tensor(k)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> result                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span>No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">\"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title LoRAを設定 　★ memo:　majicMIX_realistic_v6（アジア美女：リアル）,　stable-diffusion-v1-5（猫：リアル） { display-mode: \"form\" }\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "\n",
        "#画像生成に使うモデルデータ\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\" #@param [\"runwayml/stable-diffusion-v1-5\", \"emilianJR/majicMIX_realistic_v6\"]\n",
        "#画像生成に使うVAE\n",
        "vae_id = \"stabilityai/sd-vae-ft-ema\" #@param {type:\"string\"}\n",
        "vae = AutoencoderKL.from_pretrained(vae_id)\n",
        "#画像生成に使うスケジューラー\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "#パイプラインの作成\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, vae=vae, custom_pipeline=\"lpw_stable_diffusion\")\n",
        "\n",
        "# Ture / False\n",
        "\n",
        "#LoRAを読み込む\n",
        "LoRA_USE = False #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/Lora/add_detail.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha = 0.7 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "#LoRA_2を読み込む flat2 -1, LickingOralLoRA 0.5, koreanDollLikeness 0.8, DDpovbj_1ot\n",
        "LoRA_USE_2= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/Lora/flat2.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha_2 = -1 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "#LoRA_3を読み込む\n",
        "LoRA_USE_3= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha_3 = 0.6 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "#LoRA_4を読み込む\n",
        "LoRA_USE_4= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\" #@param (string)\n",
        "  LoRA_alpha_4 = 0.8 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#NSFW規制を無効化する\n",
        "if pipe.safety_checker is not None:\n",
        "  pipe.safety_checker = lambda images, **kwargs: (images, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3U5yBOIFq9i"
      },
      "outputs": [],
      "source": [
        "#@title 画像を生成 { display-mode: \"form\" }\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# txt2img出力画像の保存先（日付ごと）\n",
        "today = datetime.date.today()\n",
        "output_dir = f\"/content/drive/MyDrive/txt2img_output/{today.strftime('%Y%m%d')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "\n",
        "# ポジティブプロンプト\n",
        "prompt = \"high quality, masterpiece, HD, looking at viewer, simple background, no humans, animal, cat, realistic, animal focus closed mouth, black eyes,  lying, on side, full body, solo, white fur, gray fur\" #@param {type:\"string\"}\n",
        "\n",
        "# ネガティブプロンプト\n",
        "n_prompt = \"worst quality, low quality:1.4), (zombie, sketch, interlocked fingers,comic), nsfw\" #@param {type:\"string\"}\n",
        "\n",
        "# 生成枚数\n",
        "num_images = 3 #@param {type:\"integer\"}\n",
        "\n",
        "# seed値 ex) 11897334222\n",
        "seed = -1 #@param {type:\"integer\"}\n",
        "\n",
        "# 画像を生成して保存する関数\n",
        "def generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format):\n",
        "  # seed固定\n",
        "  # generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "  # image = pipe(prompt, negative_prompt=n_prompt, width=768, height=512, generator=generator, guidance_scale=7, num_inference_steps=20).images[0]\n",
        "\n",
        "  # seed=-1（ランダム）の場合  width=512, height=768, width=768, height=1152\n",
        "  width = 512 # @param [512, 768]\n",
        "  height = 768 # @param [512, 768, 1152]\n",
        "  guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "  num_inference_steps = 20 #@param {type:\"integer\"}\n",
        "  image = pipe(prompt, negative_prompt=n_prompt, width=width, height=height, guidance_scale=guidance_scale, num_inference_steps=num_inference_steps).images[0]\n",
        "\n",
        "  # 出力する画像の名前を生成する\n",
        "  image_name = datetime.datetime.now().strftime(file_format) + \".png\"\n",
        "\n",
        "  # 画像を保存する\n",
        "  save_location = os.path.join(output_dir, image_name)\n",
        "  image.save(save_location)\n",
        "\n",
        "# num_images分だけ画像を生成して保存する\n",
        "for i in range(num_images):\n",
        "  generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title ランタイムの接続を解除して削除 { display-mode: \"form\" }\n",
        "\n",
        "# # google.colabライブラリのインポート\n",
        "# import google.colab\n",
        "\n",
        "# # ランタイムの接続を解除して削除\n",
        "# google.colab.runtime.unassign()\n"
      ],
      "metadata": {
        "id": "GMsGW-MtjK4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}