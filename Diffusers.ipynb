{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWp1KnOyYgD8",
        "outputId": "7906eb93-418d-4947-c25b-a2f4844e6c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Driveに接続 { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE2OGdlsZZ4W"
      },
      "outputs": [],
      "source": [
        "#@title ライブラリの追加, LoRAの読み込み { display-mode: \"form\" }\n",
        "\n",
        "# !pip install diffusers==0.12.1\n",
        "# diffusers[torch] 以外の のインストール\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors >/dev/null 2>&1\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "\n",
        "def load_safetensors_lora(pipeline, checkpoint_path, LORA_PREFIX_UNET=\"lora_unet\", LORA_PREFIX_TEXT_ENCODER=\"lora_te\", alpha=0.75):\n",
        "    # load LoRA weight from .safetensors\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "\n",
        "    visited = []\n",
        "\n",
        "    # directly update weight in diffusers model\n",
        "    for key in state_dict:\n",
        "        # it is suggested to print out the key, it usually will be something like below\n",
        "        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\n",
        "\n",
        "        # as we have set the alpha beforehand, so just skip\n",
        "        if \".alpha\" in key or key in visited:\n",
        "            continue\n",
        "\n",
        "        if \"text\" in key:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_TEXT_ENCODER + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.text_encoder\n",
        "        else:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_UNET + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.unet\n",
        "\n",
        "        # find the target layer\n",
        "        temp_name = layer_infos.pop(0)\n",
        "        while len(layer_infos) > -1:\n",
        "            try:\n",
        "                curr_layer = curr_layer.__getattr__(temp_name)\n",
        "                if len(layer_infos) > 0:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "                elif len(layer_infos) == 0:\n",
        "                    break\n",
        "            except Exception:\n",
        "                if len(temp_name) > 0:\n",
        "                    temp_name += \"_\" + layer_infos.pop(0)\n",
        "                else:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "\n",
        "        pair_keys = []\n",
        "        if \"lora_down\" in key:\n",
        "            pair_keys.append(key.replace(\"lora_down\", \"lora_up\"))\n",
        "            pair_keys.append(key)\n",
        "        else:\n",
        "            pair_keys.append(key)\n",
        "            pair_keys.append(key.replace(\"lora_up\", \"lora_down\"))\n",
        "\n",
        "        # update weight\n",
        "        if len(state_dict[pair_keys[0]].shape) == 4:\n",
        "            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n",
        "        else:\n",
        "            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n",
        "\n",
        "        # update visited list\n",
        "        for item in pair_keys:\n",
        "            visited.append(item)\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbyLfEFDYlcA"
      },
      "outputs": [],
      "source": [
        "#@title LoRAを設定 { display-mode: \"both\" }\n",
        "\n",
        "# !pip install safetensors --quiet\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "\n",
        "#画像生成に使うモデルデータ\n",
        "# emilianJR/majicMIX_realistic_v6 -> 若干アジア人寄りの画像（３Dチック） 作り込みはすごい。\n",
        "# sinkinai/Beautiful-Realistic-Asians-v5 -> アジア人に特化したモデル(よりリアル。)　作り込みは足りない。\n",
        "# runwayml/stable-diffusion-v1-5　→ リアルな動物の画像を生成できる。背景は外。\n",
        "model_id = \"emilianJR/majicMIX_realistic_v6\"\n",
        "#画像生成に使うVAE\n",
        "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\")\n",
        "#画像生成に使うスケジューラー\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "#パイプラインの作成\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, vae=vae, custom_pipeline=\"lpw_stable_diffusion\")\n",
        "\n",
        "#LoRAを読み込む\n",
        "LoRA_USE = False #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/Lora/add_detail.safetensors\"#@param {type:\"string\"}\n",
        "  LoRA_alpha = 0.7 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "#LoRA_2を読み込む flat2 -1, LickingOralLoRA 0.5, koreanDollLikeness 0.8, DDpovbj_1ot\n",
        "LoRA_USE_2= False #@param {type:\"boolean\"} Ture / False\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/Lora/flat2.safetensors\"#@param {type:\"string\"}\n",
        "  LoRA_alpha_2 = -1 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "#LoRA_3を読み込む\n",
        "LoRA_USE_3= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/Lora/cohf.safetensors\"#@param {type:\"string\"}\n",
        "  LoRA_alpha_3 = 0.6 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "#LoRA_4を読み込む\n",
        "LoRA_USE_4= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/pretty-cut-rum-sama.safetensors\"#@param {type:\"string\"}\n",
        "  LoRA_alpha_4 = 0.8 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#NSFW規制を無効化する\n",
        "if pipe.safety_checker is not None:\n",
        "  pipe.safety_checker = lambda images, **kwargs: (images, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3U5yBOIFq9i"
      },
      "outputs": [],
      "source": [
        "#@title 画像を生成 { display-mode: \"both\" }\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# txt2img出力画像の保存先（日付ごと）\n",
        "today = datetime.date.today()\n",
        "output_dir = f\"/content/drive/MyDrive/txt2img_output/{today.strftime('%Y%m%d')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "\n",
        "# ポジティブプロンプト\n",
        "prompt = \"cute cat, realistic, high quality, masterpiece, HD,(adorable, white-and-gray fur), round-faced friendly\"\n",
        "\n",
        "# ネガティブプロンプト\n",
        "n_prompt = \"(worst quality, low quality:1.4), (zombie, sketch, interlocked fingers,comic), nsfw\"\n",
        "\n",
        "# 生成枚数\n",
        "num_images = 5\n",
        "\n",
        "# seed値 ex) 11897334222\n",
        "seed = -1\n",
        "\n",
        "# 画像を生成して保存する関数\n",
        "def generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format):\n",
        "  # seed固定\n",
        "  # generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "  # image = pipe(prompt, negative_prompt=n_prompt, width=768, height=512, generator=generator, guidance_scale=7, num_inference_steps=20).images[0]\n",
        "\n",
        "  # seed=-1（ランダム）の場合  width=512, height=768, width=768, height=1152\n",
        "  image = pipe(prompt, negative_prompt=n_prompt, width=512, height=768, guidance_scale=7.5, num_inference_steps=20).images[0]\n",
        "\n",
        "  # 出力する画像の名前を生成する\n",
        "  image_name = datetime.datetime.now().strftime(file_format) + \".png\"\n",
        "\n",
        "  # 画像を保存する\n",
        "  save_location = os.path.join(output_dir, image_name)\n",
        "  image.save(save_location)\n",
        "\n",
        "# num_images分だけ画像を生成して保存する\n",
        "for i in range(num_images):\n",
        "  generate_and_save_image(prompt, n_prompt, seed, output_dir, file_format)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google.colabライブラリのインポート\n",
        "import google.colab\n",
        "\n",
        "# ランタイムの接続を解除して削除\n",
        "google.colab.runtime.unassign()\n"
      ],
      "metadata": {
        "id": "GMsGW-MtjK4K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}