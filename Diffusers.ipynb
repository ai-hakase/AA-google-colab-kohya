{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Diffusers ライブラリを用いて、画像を生成するスクリプト。**\n",
        "\n",
        "[Github](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers.ipynb)"
      ],
      "metadata": {
        "id": "FDWXJo4TqbdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JE2OGdlsZZ4W"
      },
      "outputs": [],
      "source": [
        "#@title ① Driveに接続, ライブラリの追加, LoRAの読み込み { display-mode: \"form\" }\n",
        "\n",
        "# Driveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# ライブラリの追加\n",
        "# !pip install diffusers==0.12.1\n",
        "# diffusers[torch] 以外の のインストール\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion\n",
        "\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "\n",
        "def load_safetensors_lora(pipeline, checkpoint_path, LORA_PREFIX_UNET=\"lora_unet\", LORA_PREFIX_TEXT_ENCODER=\"lora_te\", alpha=0.75):\n",
        "    # load LoRA weight from .safetensors\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "\n",
        "    visited = []\n",
        "\n",
        "    # directly update weight in diffusers model\n",
        "    for key in state_dict:\n",
        "        # it is suggested to print out the key, it usually will be something like below\n",
        "        # \"lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight\"\n",
        "\n",
        "        # as we have set the alpha beforehand, so just skip\n",
        "        if \".alpha\" in key or key in visited:\n",
        "            continue\n",
        "\n",
        "        if \"text\" in key:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_TEXT_ENCODER + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.text_encoder\n",
        "        else:\n",
        "            layer_infos = key.split(\".\")[0].split(LORA_PREFIX_UNET + \"_\")[-1].split(\"_\")\n",
        "            curr_layer = pipeline.unet\n",
        "\n",
        "        # find the target layer\n",
        "        temp_name = layer_infos.pop(0)\n",
        "        while len(layer_infos) > -1:\n",
        "            try:\n",
        "                curr_layer = curr_layer.__getattr__(temp_name)\n",
        "                if len(layer_infos) > 0:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "                elif len(layer_infos) == 0:\n",
        "                    break\n",
        "            except Exception:\n",
        "                if len(temp_name) > 0:\n",
        "                    temp_name += \"_\" + layer_infos.pop(0)\n",
        "                else:\n",
        "                    temp_name = layer_infos.pop(0)\n",
        "\n",
        "        pair_keys = []\n",
        "        if \"lora_down\" in key:\n",
        "            pair_keys.append(key.replace(\"lora_down\", \"lora_up\"))\n",
        "            pair_keys.append(key)\n",
        "        else:\n",
        "            pair_keys.append(key)\n",
        "            pair_keys.append(key.replace(\"lora_up\", \"lora_down\"))\n",
        "\n",
        "        # update weight\n",
        "        if len(state_dict[pair_keys[0]].shape) == 4:\n",
        "            weight_up = state_dict[pair_keys[0]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].squeeze(3).squeeze(2).to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down).unsqueeze(2).unsqueeze(3)\n",
        "        else:\n",
        "            weight_up = state_dict[pair_keys[0]].to(torch.float32)\n",
        "            weight_down = state_dict[pair_keys[1]].to(torch.float32)\n",
        "            curr_layer.weight.data += alpha * torch.mm(weight_up, weight_down)\n",
        "\n",
        "        # update visited list\n",
        "        for item in pair_keys:\n",
        "            visited.append(item)\n",
        "\n",
        "    return pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbyLfEFDYlcA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title ② LoRAを設定 　★ memo:　majicMIX_realistic_v6（アジア美女：リアル）,　stable-diffusion-v1-5（猫：リアル） { display-mode: \"form\" }\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "import torch\n",
        "\n",
        "#画像生成に使うモデルデータ\n",
        "model_id = \"emilianJR/majicMIX_realistic_v6\" #@param [\"runwayml/stable-diffusion-v1-5\", \"emilianJR/majicMIX_realistic_v6\"]\n",
        "#画像生成に使うVAE\n",
        "vae_id = \"stabilityai/sd-vae-ft-mse\" #@param {type:\"string\"}\n",
        "vae = AutoencoderKL.from_pretrained(vae_id)\n",
        "#画像生成に使うスケジューラー\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "\n",
        "#パイプラインの作成\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, vae=vae, custom_pipeline=\"lpw_stable_diffusion\")\n",
        "\n",
        "# Ture / False\n",
        "\n",
        "#LoRAを読み込む\n",
        "LoRA_USE = False #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/Lora/add_detail.safetensors\" #@param [\"/content/drive/MyDrive/Lora/flat2.safetensors\", \"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\", \"/content/drive/MyDrive/Lora/pretty-cat-rum-sama.safetensors\", \"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\", \"/content/drive/MyDrive/Lora/add_detail.safetensors\"]\n",
        "  LoRA_alpha = 0.5 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "#LoRA_2を読み込む flat2 -1, LickingOralLoRA 0.5, koreanDollLikeness 0.8, DDpovbj_1ot\n",
        "LoRA_USE_2= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/Lora/flat2.safetensors\" #@param (string)\n",
        "  LoRA_alpha_2 = 0.1 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "#LoRA_3を読み込む\n",
        "LoRA_USE_3= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/Lora/koreanDollLikeness.safetensors\" #@param (string)\n",
        "  LoRA_alpha_3 = 0.3 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "#LoRA_4を読み込む\n",
        "LoRA_USE_4= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\" #@param (string)\n",
        "  LoRA_alpha_4 = 0.5 #@param {type:\"number\"}\n",
        "  pipe = load_safetensors_lora(pipe, LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#NSFW規制を無効化する\n",
        "if pipe.safety_checker is not None:\n",
        "  pipe.safety_checker = lambda images, **kwargs: (images, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3U5yBOIFq9i"
      },
      "outputs": [],
      "source": [
        "#@title ③ 画像を生成とZIPのダウンロード ＋ 終わったフォルダを移動 { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "# 必要なモジュールやライブラリをインポートする\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# パラメータを辞書型でまとめる関数\n",
        "def form_dict():\n",
        "  prompt = \"Beautiful girl in micro bikini,(masterpiece),((super detailed)),(expressionless)), realistic8K UHD,(best quality:1. 2), high definition, exquisite details, fine texture, high detail, fine beautiful delicate eyes, perfectly proportioned face, light particles, distinct_ image, high resolution, high quality textures and shadows, realistic and beautiful face with big eyes, blush, glossy lips and perfect proportions, depth of field, lens flare, ray tracing, perspective, prominent nose, slender face, perfectly toned body, (thin waist:1. 3), medium chest, (glossy (glossy skin), (pureerosface_v1:0.5), (ulzzang-6500-v1.1:0.5), (sweat is visible on her body due to her strenuous exercise, her clothes are soaked and see through: 1. 2)), braun short hair, sitting, (spreading legs:1.5)), ((low angle,camel toes)), (exposed bikini:1.4)BREAK (smiling, embarrassed), nsfw ,in pool\" # @param {type:\"string\"}\n",
        "  n_prompt = \"painting, sketch, (worst picture quality:2), (low quality:2), (normal quality:2), bad feet, lowres, ((monochrome)), skin blemishes, acne, skin blemishes, bad anatomy, bad hands, text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, crossed eyes, very low resolution, bad proportions,(ng_deepnegative_v1_75t),(negative_hand-neg)\" # @param {type:\"string\"}\n",
        "  num_images = 5 # @param {type:\"integer\"}\n",
        "  isFixSeed = False # @param {type:\"boolean\"}\n",
        "  seed = -1 # @param {type:\"integer\"}\n",
        "  width = \"768\" # @param [512, 768, 1024]\n",
        "  height = \"1024\" # @param [512, 768, 1024, 1536]\n",
        "  guidance_scale = 7 # @param {type:\"number\"}\n",
        "  num_inference_steps = 60 # @param {type:\"integer\"}\n",
        "\n",
        "  return locals()\n",
        "\n",
        "# パラメータを辞書型で取得する\n",
        "params = form_dict()\n",
        "\n",
        "\n",
        "# 画像を生成して保存する関数\n",
        "def generate_and_save_image(prompt, n_prompt, isFixSeed,seed, width, height, guidance_scale, num_inference_steps):\n",
        "\n",
        "  # isFixSeedとseedの値に応じてgeneratorを作成する\n",
        "  if isFixSeed and seed != -1: # seed固定して同じ画像を生成する場合\n",
        "    generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "  else: # seed=-1（ランダム）の場合\n",
        "    generator = None\n",
        "\n",
        "  # テキストから画像を生成する\n",
        "  image = pipe(prompt,\n",
        "                negative_prompt=n_prompt,\n",
        "                width=int(width),\n",
        "                height=int(height),\n",
        "                generator=generator,\n",
        "                guidance_scale=guidance_scale,\n",
        "                num_inference_steps=num_inference_steps).images[0]\n",
        "\n",
        "  # 出力する画像の名前を生成する\n",
        "  image_name = datetime.datetime.now().strftime(file_format) + \".png\"\n",
        "\n",
        "  # 画像を保存する\n",
        "  save_location = os.path.join(output_dir, image_name)\n",
        "  image.save(save_location)\n",
        "\n",
        "  # 生成した画像の名前と保存先を返す\n",
        "  return image_name, save_location\n",
        "\n",
        "\n",
        "# ダウンロード済のフォルダの移動先フォルダを作る\n",
        "end_downloading_dir = \"/content/drive/MyDrive/End-downloading2\" # @param {type:\"string\"}\n",
        "os.makedirs(end_downloading_dir, exist_ok=True)\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマット\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "\n",
        "\n",
        "# 画像を生成とZIPのダウンロード ＋ 終わったフォルダを移動\n",
        "for j in range(10):\n",
        "\n",
        "  # txt2img出力画像の保存先（日付ごと）\n",
        "  now = datetime.datetime.now()\n",
        "  output_dir = f\"/content/drive/MyDrive/txt2img_output-{now.strftime(file_format)}\"\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "  # num_images分だけ画像を生成して保存する\n",
        "  image_names = [] # 生成した画像の名前のリスト\n",
        "  for i in range(params[\"num_images\"]):\n",
        "    image_name, save_location = generate_and_save_image(params[\"prompt\"], params[\"n_prompt\"], params[\"isFixSeed\"], params[\"seed\"], params[\"width\"], params[\"height\"], params[\"guidance_scale\"], params[\"num_inference_steps\"])\n",
        "    image_names.append(image_name)\n",
        "\n",
        "  # ファイル名を生成する\n",
        "  file_name = output_dir.split(\"/\")[-1]\n",
        "\n",
        "  # フォルダをzip圧縮する\n",
        "  shutil.make_archive(file_name, 'zip', output_dir)\n",
        "\n",
        "  # Zipをダウンロード\n",
        "  files.download(f'/content/{file_name}.zip')\n",
        "\n",
        "  # 終わったらフォルダを別の場所に移動する\n",
        "  shutil.move(os.path.join(\"/content/drive/MyDrive\", file_name), end_downloading_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}