{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_ControlNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWXJo4TqbdN"
      },
      "source": [
        "## **Diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ã¦ã€ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚**\n",
        "å‚è€ƒ ï¼š\n",
        "[æ—¥æœ¬èª](https://blog.shikoan.com/controlnet_lora/#ControlNet%EF%BC%88%E3%83%9D%E3%83%BC%E3%82%BA%EF%BC%89%E3%82%92%E4%BD%BF%E3%81%86)  ,\n",
        "[è‹±èª](https://huggingface.co/blog/controlnet) ,\n",
        "[Github - AA-google-colab-kohya](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveã«æ¥ç¶š, ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ  { display-mode: \"form\" }\n",
        "\n",
        "# Driveã«æ¥ç¶š\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ \n",
        "# æœ€æ–°ç‰ˆï¼ˆ0.18.0ï¼‰\n",
        "!pip install git+https://github.com/huggingface/diffusers >/dev/null 2>&1\n",
        "# diffusers==0.17.1\n",
        "!pip install --upgrade transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion >/dev/null 2>&1\n",
        "!pip install --upgrade xformers git+https://github.com/huggingface/accelerate.git >/dev/null 2>&1\n",
        "!pip install opencv-contrib-python >/dev/null 2>&1\n",
        "!pip install controlnet_aux >/dev/null 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "2_jumxegTi0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title è‡ªå‹•åˆ‡æ–­ã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹ã‚³ãƒ¼ãƒ‰ { display-mode: \"form\" }\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "XesbQoV9Igeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ***\n",
        "\n",
        "#@title ControlNet ã®æº–å‚™ { display-mode: \"form\" }\n",
        "\n",
        "# ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¤œç´¢ã™ã‚‹\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler, StableDiffusionImg2ImgPipeline) # + VAEModel (0.18.0)\n",
        "from diffusers.utils import numpy_to_pil\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "\n",
        "# controlnet_auxã¨ã„ã†ãƒãƒ¼ã‚ºæ¤œå‡ºã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "# PyTorchã¨ã„ã†æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import torch\n",
        "\n",
        "# PILã¨ã„ã†ç”»åƒå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from PIL import Image\n",
        "\n",
        "# JPEGãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "# @markdown ***ãƒãƒ¼ã‚¸ãƒ³ã‚°å­¦ç¿’ç”¨ãƒ•ã‚©ãƒ«ãƒ€***\n",
        "dir = \"/content/drive/MyDrive/StableDiffusion/ControlNet/spread_legs\" #@param {type: \"string\"}\n",
        "extension = \"*.png\" #@param {type: \"string\"}\n",
        "images_path = os.path.join(dir, extension)\n",
        "jpeg_files = glob.glob(images_path)\n",
        "\n",
        "# ãƒãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹\n",
        "poses = []\n",
        "isOpenpose = True # @param {type:\"boolean\"}\n",
        "if isOpenpose:\n",
        "  # ãƒãƒ¼ã‚ºã‚’æ¤œå‡ºã™ã‚‹\n",
        "  controlnet_check_path = \"lllyasviel/ControlNet\" #@param {type: \"string\"}\n",
        "  pose_detector = OpenposeDetector.from_pretrained(controlnet_check_path) # äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
        "  for file in jpeg_files:\n",
        "      # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ¼ã‚ºã‚’æ¤œå‡ºã™ã‚‹\n",
        "      p = pose_detector(Image.open(file))\n",
        "      # ãƒãƒ¼ã‚ºã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹\n",
        "      poses.append(p)\n",
        "\n",
        "# ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’èª­ã¿è¾¼ã‚€ lllyasviel/sd-controlnet-openpose\n",
        "controlnet_model_path = \"lpw/stable_diffusion\"  #@param {type: \"string\"}\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ‡ãƒ¼ã‚¿å‹ã¯float16ã«æŒ‡å®šã™ã‚‹\n",
        "controlnet = ControlNetModel.from_pretrained(controlnet_model_path, torch_dtype=torch.float16)\n",
        "\n",
        "# @markdown ***\n"
      ],
      "metadata": {
        "id": "A4nXGvyCEW5z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ***\n",
        "\n",
        "# @title Modelã€LoRA ã‚’ StableDiffusionControlNetPipeline ã«è¨­å®š  â€»LoRA ã®å¯¾å¿œãŒã¾ã ã€€{ display-mode: \"form\" }\n",
        "\n",
        "#ãƒ¢ãƒ‡ãƒ«\n",
        "# @markdown ğŸ‘š Model\n",
        "model_path = \"emilianJR/majicMIX_realistic_v6\" #@param {type:\"string\"}\n",
        "\n",
        "device=\"cuda\"\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    # custom_pipeline=\"lpw_stable_diffusion\",\n",
        ")\n",
        "\n",
        "# VAE ã‚’èª­ã¿è¾¼ã‚€\n",
        "# vae_path = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
        "# vae = VAEModel.from_pretrained(vae_path)\n",
        "\n",
        "# LoRAã‚’è¿½åŠ  /content/drive/MyDrive/StableDiffusion/Lora/japaneseDollLikeness_v15.safetensors\n",
        "# lora_path = \"Kanbara/doll-likeness-series/japaneseDollLikeness_v15.safetensors\" #@param {type:\"string\"}\n",
        "# pipe.unet.load_attn_procs(lora_path)\n",
        "\n",
        "# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’è¨­å®š\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# @markdown ğŸ‘™ NSFWã‚’è¡¨ç¤ºã™ã‚‹è¨­å®š\n",
        "# Disabling safety checker\n",
        "isSafeNsfwOn = True  #@param {type:\"boolean\"}\n",
        "if isSafeNsfwOn == True:\n",
        "    pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "else:\n",
        "    pipe.safety_checker = lambda images, **kwargs: (images, [True] * len(images))\n",
        "\n",
        "pipe.to(device)\n",
        "\n",
        "# @markdown ***"
      ],
      "metadata": {
        "id": "gy6PQuFAE2JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ç”»åƒç”Ÿæˆã‚’å®Ÿè¡Œ { display-mode: \"form\" }\n",
        "\n",
        "# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ã†æ—¥ä»˜ã¨æ™‚åˆ»ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã™ã‚‹\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "i=0\n",
        "\n",
        "# ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—\n",
        "jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "\n",
        "# @markdown ***\n",
        "#txt2imgå‡ºåŠ›ç”»åƒã®ä¿å­˜å…ˆ\n",
        "#@markdown ***ğŸ“‚ å‡ºåŠ›ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€***\n",
        "save_path = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/bikini_controlnet/\" #@param {type: \"string\"}\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "# @markdown ***\n",
        "\n",
        "#@@markdown ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "prompt = \"Beautiful girl in bikini, sitting, (spreading legs:1.5),(very wet body, clothes are very soaked:1.2),(masterpiece),((super detailed)), realistic8K UHD,(best quality:1. 2), high definition, exquisite details, fine texture, high detail, fine beautiful delicate eyes, perfectly proportioned face, light particles, distinct_ image, high resolution, high quality textures and shadows, realistic and beautiful face with big eyes, blush, glossy lips and perfect proportions, depth of field, lens flare, ray tracing, perspective, prominent nose, slender face, perfectly toned body, (thin waist:1. 3), medium chest, (glossy hands),(glossy skin), (pureerosface_v1:0.5), braun short hair, ((low angle,camel toes)), (exposed bikini pantus:1.4)BREAK (smiling, embarrassed), nsfw ,in beach\" #@param {type:\"string\"}\n",
        "#@@markdown ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "negative = \"(ng_deepnegative_v1_75t),(negative_hand-neg:1.2),painting, sketch, (worst picture quality:2), (low quality:2), (normal quality:2), bad feet, lowres, ((monochrome)),skin blemishes, acne, skin blemishes, bad anatomy, (bad fingers, bad hands, missing fingers:1.3), text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, crossed eyes, very low resolution, bad proportions\" #@param {type:\"string\"}\n",
        "#@markdown ***ğŸ–¼ å‡ºåŠ›æšæ•°***\n",
        "batch_count = 200 #@param {type: \"integer\"}\n",
        "#@markdown ***ğŸ¦µ ã‚¹ãƒ†ãƒƒãƒ—æ•°***\n",
        "steps = 60 #@param {type:\"integer\"}\n",
        "#@@markdown ç”»åƒã‚µã‚¤ã‚º\n",
        "img_width = \"1024\" # @param [512, 768, 1024, 1536]\n",
        "img_height = \"1536\" # @param [512, 768, 1024, 1536]\n",
        "#@@markdown CFG\n",
        "CFG = 8 #@param {type: \"number\"}\n",
        "#@@markdown ã‚·ãƒ¼ãƒ‰ï¼ˆ-1ã®æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼‰\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "if seed is None or seed == -1:\n",
        "  inputSeed = random.randint(0, 2147483647)\n",
        "else:\n",
        "  valueSeed = seed\n",
        "\n",
        "# run stable diffusion\n",
        "images = []\n",
        "generator = torch.Generator(device)\n",
        "\n",
        "for i in range(batch_count):\n",
        "\n",
        "  if seed is None or seed == -1: valueSeed = inputSeed + i\n",
        "  poseIndex = random.randint(0, len(poses) - 1)\n",
        "  generator.manual_seed(valueSeed)\n",
        "\n",
        "  image = pipe(\n",
        "    prompt,\n",
        "    poses[poseIndex],\n",
        "    negative_prompt=negative,\n",
        "    generator=generator,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=CFG,\n",
        "    width=int(img_width),\n",
        "    height=int(img_height),\n",
        "    output_type=\"pil\",\n",
        "  )\n",
        "\n",
        "  # ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—\n",
        "  jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  #å‡ºåŠ›ã™ã‚‹ç”»åƒã®åå‰ã‚’ç”Ÿæˆã™ã‚‹\n",
        "  file_name = (jst_now.strftime(file_format)+ \"_\" + str(valueSeed))\n",
        "  image_name = file_name + f\".png\"\n",
        "\n",
        "  #ç”»åƒã‚’ä¿å­˜ã™ã‚‹\n",
        "  save_location = os.path.join(save_path, image_name)\n",
        "\n",
        "  # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "  images = image.images\n",
        "\n",
        "  # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®æ•°ã‚’å–å¾—\n",
        "  num_images = len(images)\n",
        "\n",
        "  # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’é †ç•ªã«ä¿å­˜\n",
        "  for i in range(num_images):\n",
        "    # ç”»åƒã‚’å–ã‚Šå‡ºã™\n",
        "    image = images[i]\n",
        "\n",
        "    # @markdown ***\n",
        "    #@markdown ***âœ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿***\n",
        "    save_metadata = True #@param {type: \"boolean\"}\n",
        "    if save_metadata:\n",
        "      metadata = PngInfo()\n",
        "      metadata.add_text(\"prompt\",(prompt))\n",
        "      metadata.add_text(\"negative\",(negative))\n",
        "      metadata.add_text(\"steps\",(str(steps)))\n",
        "      metadata.add_text(\"CFG\",(str(CFG)))\n",
        "      metadata.add_text(\"width\",(str(img_width)))\n",
        "      metadata.add_text(\"height\",(str(img_height)))\n",
        "      metadata.add_text(\"seed\",str((valueSeed)))\n",
        "      image.save(save_location, pnginfo=metadata)\n",
        "\n",
        "    # dst = Image.new('RGB', (image.shape[1], image.shape[0]))\n",
        "    # dst.paste(output, (0, 0))\n",
        "\n",
        "    # # ç”»åƒä¿å­˜ã€‚googleãƒ‰ãƒ©ã‚¤ãƒ–ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã€å¹´æœˆæ—¥æ™‚åˆ†ç§’ã‹ã‚‰ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜\n",
        "    # filename = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y%m%d%H%M%S')\n",
        "    # dst.save(out_dir+'/'+filename+'.png')\n",
        "\n",
        "    # dst # ç”»åƒè¡¨ç¤º\n",
        "\n",
        "    # @markdown ***\n"
      ],
      "metadata": {
        "id": "tJ9NqU4F8UpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "00498b18-77f8-4988-d5dd-7eaf672b3e08"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3f6dd96c6e4d>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   image = pipe(\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposeIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: StableDiffusionLongPromptWeightingPipeline.__call__() got multiple values for argument 'negative_prompt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIVx0EDv0Z7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›\n",
        "\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "#@markdown **ä¿å­˜ã—ãŸç”»åƒã®ãƒ‘ã‚¹**\n",
        "file_dir = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/\"  #@param {type: \"string\"}\n",
        "file_name = \"20230707_235255_101570535.png\" #@param {type: \"string\"}\n",
        "file_path = os.path.join(file_dir, file_name)\n",
        "img = Image.open(file_path)\n",
        "\n",
        "print(\"Prompt: \",img.text[\"prompt\"])\n",
        "print(\"Negative Prompt: \",img.text[\"negative\"])\n",
        "print(\"Scheduler: \", img.text[\"scheduler\"])\n",
        "print(\"Steps: \",img.text[\"steps\"])\n",
        "print(\"CFG: \",img.text[\"CFG\"])\n",
        "print(\"Width: \",img.text[\"width\"])\n",
        "print(\"Height: \",img.text[\"height\"])\n",
        "print(\"Seed: \",img.text[\"seed\"])\n",
        "\n",
        "try:\n",
        "  print(\"Upscaling ratio; \",img.text[\"upscaling ratio\"])\n",
        "  print(\"Up steps: \",img.text[\"up steps\"])\n",
        "  print(\"Denoising strength: \",img.text[\"denoising strength\"])\n",
        "except:\n",
        "  print(\"Hires.fix was OFF.\")\n",
        "\n",
        "# %%writefile output.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}