{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_ControlNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWXJo4TqbdN"
      },
      "source": [
        "## **Diffusers ライブラリを用いて、画像を生成するスクリプト。**\n",
        "参考 ：\n",
        "[日本語](https://blog.shikoan.com/controlnet_lora/#ControlNet%EF%BC%88%E3%83%9D%E3%83%BC%E3%82%BA%EF%BC%89%E3%82%92%E4%BD%BF%E3%81%86)  ,\n",
        "[英語](https://huggingface.co/blog/controlnet) ,\n",
        "[Github - AA-google-colab-kohya](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveに接続, ライブラリの追加 { display-mode: \"form\" }\n",
        "\n",
        "# Driveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ライブラリの追加\n",
        "# 最新版（0.18.0）\n",
        "!pip install git+https://github.com/huggingface/diffusers >/dev/null 2>&1\n",
        "# diffusers==0.17.1\n",
        "!pip install --upgrade transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion >/dev/null 2>&1\n",
        "!pip install --upgrade xformers git+https://github.com/huggingface/accelerate.git >/dev/null 2>&1\n",
        "!pip install opencv-contrib-python >/dev/null 2>&1\n",
        "!pip install controlnet_aux >/dev/null 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "2_jumxegTi0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 自動切断されないようにするコード { display-mode: \"form\" }\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "XesbQoV9Igeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ***\n",
        "\n",
        "#@title ControlNet の準備 { display-mode: \"form\" }\n",
        "\n",
        "# ワイルドカードを使ってファイルパスを検索する\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# diffusers ライブラリをインポートする\n",
        "from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler, StableDiffusionImg2ImgPipeline) # + VAEModel (0.18.0)\n",
        "from diffusers.utils import numpy_to_pil\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "\n",
        "# controlnet_auxというポーズ検出のライブラリをインポートする\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "# PyTorchという深層学習フレームワークをインポートする\n",
        "import torch\n",
        "\n",
        "# PILという画像処理ライブラリをインポートする\n",
        "from PIL import Image\n",
        "\n",
        "# JPEGファイルのパスのリストを取得\n",
        "# @markdown ***ポージング学習用フォルダ***\n",
        "dir = \"/content/drive/MyDrive/StableDiffusion/ControlNet/spread_legs\" #@param {type: \"string\"}\n",
        "extension = \"*.png\" #@param {type: \"string\"}\n",
        "images_path = os.path.join(dir, extension)\n",
        "jpeg_files = glob.glob(images_path)\n",
        "\n",
        "# ポーズのリストを作成する\n",
        "poses = []\n",
        "isOpenpose = True # @param {type:\"boolean\"}\n",
        "if isOpenpose:\n",
        "  # ポーズを検出する\n",
        "  controlnet_check_path = \"lllyasviel/ControlNet\" #@param {type: \"string\"}\n",
        "  pose_detector = OpenposeDetector.from_pretrained(controlnet_check_path) # 事前学習済みのモデルを読み込む\n",
        "  for file in jpeg_files:\n",
        "      # ファイルパスから画像を読み込んでポーズを検出する\n",
        "      p = pose_detector(Image.open(file))\n",
        "      # ポーズをリストに追加する\n",
        "      poses.append(p)\n",
        "\n",
        "# コントロールネットワークを読み込む lllyasviel/sd-controlnet-openpose\n",
        "controlnet_model_path = \"lpw/stable_diffusion\"  #@param {type: \"string\"}\n",
        "# 事前学習済みのモデルを読み込む。データ型はfloat16に指定する\n",
        "controlnet = ControlNetModel.from_pretrained(controlnet_model_path, torch_dtype=torch.float16)\n",
        "\n",
        "# @markdown ***\n"
      ],
      "metadata": {
        "id": "A4nXGvyCEW5z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ***\n",
        "\n",
        "# @title Model、LoRA を StableDiffusionControlNetPipeline に設定  ※LoRA の対応がまだ　{ display-mode: \"form\" }\n",
        "\n",
        "#モデル\n",
        "# @markdown 👚 Model\n",
        "model_path = \"emilianJR/majicMIX_realistic_v6\" #@param {type:\"string\"}\n",
        "\n",
        "device=\"cuda\"\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    # custom_pipeline=\"lpw_stable_diffusion\",\n",
        ")\n",
        "\n",
        "# VAE を読み込む\n",
        "# vae_path = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
        "# vae = VAEModel.from_pretrained(vae_path)\n",
        "\n",
        "# LoRAを追加 /content/drive/MyDrive/StableDiffusion/Lora/japaneseDollLikeness_v15.safetensors\n",
        "# lora_path = \"Kanbara/doll-likeness-series/japaneseDollLikeness_v15.safetensors\" #@param {type:\"string\"}\n",
        "# pipe.unet.load_attn_procs(lora_path)\n",
        "\n",
        "# スケジューラーを設定\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# @markdown 👙 NSFWを表示する設定\n",
        "# Disabling safety checker\n",
        "isSafeNsfwOn = True  #@param {type:\"boolean\"}\n",
        "if isSafeNsfwOn == True:\n",
        "    pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "else:\n",
        "    pipe.safety_checker = lambda images, **kwargs: (images, [True] * len(images))\n",
        "\n",
        "pipe.to(device)\n",
        "\n",
        "# @markdown ***"
      ],
      "metadata": {
        "id": "gy6PQuFAE2JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 画像生成を実行 { display-mode: \"form\" }\n",
        "\n",
        "# 必要なモジュールやライブラリをインポートする\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "i=0\n",
        "\n",
        "# 現在の日本時間を取得\n",
        "jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "\n",
        "# @markdown ***\n",
        "#txt2img出力画像の保存先\n",
        "#@markdown ***📂 出力画像を保存するフォルダ***\n",
        "save_path = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/bikini_controlnet/\" #@param {type: \"string\"}\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "# @markdown ***\n",
        "\n",
        "#@@markdown ポジティブプロンプト\n",
        "prompt = \"Beautiful girl in bikini, sitting, (spreading legs:1.5),(very wet body, clothes are very soaked:1.2),(masterpiece),((super detailed)), realistic8K UHD,(best quality:1. 2), high definition, exquisite details, fine texture, high detail, fine beautiful delicate eyes, perfectly proportioned face, light particles, distinct_ image, high resolution, high quality textures and shadows, realistic and beautiful face with big eyes, blush, glossy lips and perfect proportions, depth of field, lens flare, ray tracing, perspective, prominent nose, slender face, perfectly toned body, (thin waist:1. 3), medium chest, (glossy hands),(glossy skin), (pureerosface_v1:0.5), braun short hair, ((low angle,camel toes)), (exposed bikini pantus:1.4)BREAK (smiling, embarrassed), nsfw ,in beach\" #@param {type:\"string\"}\n",
        "#@@markdown ネガティブプロンプト\n",
        "negative = \"(ng_deepnegative_v1_75t),(negative_hand-neg:1.2),painting, sketch, (worst picture quality:2), (low quality:2), (normal quality:2), bad feet, lowres, ((monochrome)),skin blemishes, acne, skin blemishes, bad anatomy, (bad fingers, bad hands, missing fingers:1.3), text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, crossed eyes, very low resolution, bad proportions\" #@param {type:\"string\"}\n",
        "#@markdown ***🖼 出力枚数***\n",
        "batch_count = 200 #@param {type: \"integer\"}\n",
        "#@markdown ***🦵 ステップ数***\n",
        "steps = 60 #@param {type:\"integer\"}\n",
        "#@@markdown 画像サイズ\n",
        "img_width = \"1024\" # @param [512, 768, 1024, 1536]\n",
        "img_height = \"1536\" # @param [512, 768, 1024, 1536]\n",
        "#@@markdown CFG\n",
        "CFG = 8 #@param {type: \"number\"}\n",
        "#@@markdown シード（-1の時はランダム）\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "if seed is None or seed == -1:\n",
        "  inputSeed = random.randint(0, 2147483647)\n",
        "else:\n",
        "  valueSeed = seed\n",
        "\n",
        "# run stable diffusion\n",
        "images = []\n",
        "generator = torch.Generator(device)\n",
        "\n",
        "for i in range(batch_count):\n",
        "\n",
        "  if seed is None or seed == -1: valueSeed = inputSeed + i\n",
        "  poseIndex = random.randint(0, len(poses) - 1)\n",
        "  generator.manual_seed(valueSeed)\n",
        "\n",
        "  image = pipe(\n",
        "    prompt,\n",
        "    poses[poseIndex],\n",
        "    negative_prompt=negative,\n",
        "    generator=generator,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=CFG,\n",
        "    width=int(img_width),\n",
        "    height=int(img_height),\n",
        "    output_type=\"pil\",\n",
        "  )\n",
        "\n",
        "  # 現在の日本時間を取得\n",
        "  jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  #出力する画像の名前を生成する\n",
        "  file_name = (jst_now.strftime(file_format)+ \"_\" + str(valueSeed))\n",
        "  image_name = file_name + f\".png\"\n",
        "\n",
        "  #画像を保存する\n",
        "  save_location = os.path.join(save_path, image_name)\n",
        "\n",
        "  # 生成された画像のリストを取得\n",
        "  images = image.images\n",
        "\n",
        "  # 生成された画像の数を取得\n",
        "  num_images = len(images)\n",
        "\n",
        "  # 生成された画像を順番に保存\n",
        "  for i in range(num_images):\n",
        "    # 画像を取り出す\n",
        "    image = images[i]\n",
        "\n",
        "    # @markdown ***\n",
        "    #@markdown ***✎ メタデータの書き込み***\n",
        "    save_metadata = True #@param {type: \"boolean\"}\n",
        "    if save_metadata:\n",
        "      metadata = PngInfo()\n",
        "      metadata.add_text(\"prompt\",(prompt))\n",
        "      metadata.add_text(\"negative\",(negative))\n",
        "      metadata.add_text(\"steps\",(str(steps)))\n",
        "      metadata.add_text(\"CFG\",(str(CFG)))\n",
        "      metadata.add_text(\"width\",(str(img_width)))\n",
        "      metadata.add_text(\"height\",(str(img_height)))\n",
        "      metadata.add_text(\"seed\",str((valueSeed)))\n",
        "      image.save(save_location, pnginfo=metadata)\n",
        "\n",
        "    # dst = Image.new('RGB', (image.shape[1], image.shape[0]))\n",
        "    # dst.paste(output, (0, 0))\n",
        "\n",
        "    # # 画像保存。googleドライブの出力ディレクトリに、年月日時分秒からなるファイル名で保存\n",
        "    # filename = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y%m%d%H%M%S')\n",
        "    # dst.save(out_dir+'/'+filename+'.png')\n",
        "\n",
        "    # dst # 画像表示\n",
        "\n",
        "    # @markdown ***\n"
      ],
      "metadata": {
        "id": "tJ9NqU4F8UpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "00498b18-77f8-4988-d5dd-7eaf672b3e08"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3f6dd96c6e4d>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueSeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   image = pipe(\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposeIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: StableDiffusionLongPromptWeightingPipeline.__call__() got multiple values for argument 'negative_prompt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIVx0EDv0Z7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 画像のメタデータを出力\n",
        "\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "#@markdown **保存した画像のパス**\n",
        "file_dir = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/\"  #@param {type: \"string\"}\n",
        "file_name = \"20230707_235255_101570535.png\" #@param {type: \"string\"}\n",
        "file_path = os.path.join(file_dir, file_name)\n",
        "img = Image.open(file_path)\n",
        "\n",
        "print(\"Prompt: \",img.text[\"prompt\"])\n",
        "print(\"Negative Prompt: \",img.text[\"negative\"])\n",
        "print(\"Scheduler: \", img.text[\"scheduler\"])\n",
        "print(\"Steps: \",img.text[\"steps\"])\n",
        "print(\"CFG: \",img.text[\"CFG\"])\n",
        "print(\"Width: \",img.text[\"width\"])\n",
        "print(\"Height: \",img.text[\"height\"])\n",
        "print(\"Seed: \",img.text[\"seed\"])\n",
        "\n",
        "try:\n",
        "  print(\"Upscaling ratio; \",img.text[\"upscaling ratio\"])\n",
        "  print(\"Up steps: \",img.text[\"up steps\"])\n",
        "  print(\"Denoising strength: \",img.text[\"denoising strength\"])\n",
        "except:\n",
        "  print(\"Hires.fix was OFF.\")\n",
        "\n",
        "# %%writefile output.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}