{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_ControlNet_Canva_ipnb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWXJo4TqbdN"
      },
      "source": [
        "## **Diffusers ライブラリを用いて、画像を生成するスクリプト。　（７７文字制限あり。）**\n",
        "参考 ：\n",
        "[日本語](https://blog.shikoan.com/controlnet_lora/#ControlNet%EF%BC%88%E3%83%9D%E3%83%BC%E3%82%BA%EF%BC%89%E3%82%92%E4%BD%BF%E3%81%86)  ,\n",
        "[英語](https://huggingface.co/blog/controlnet) ,\n",
        "[Github - AA-google-colab-kohya](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveに接続, ライブラリの追加 { display-mode: \"form\" }\n",
        "\n",
        "# Driveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ライブラリの追加\n",
        "# 最新版（0.18.0）\n",
        "# !pip install git+https://github.com/huggingface/diffusers >/dev/null 2>&1\n",
        "# diffusers==0.17.1\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion >/dev/null 2>&1\n",
        "!pip install --upgrade xformers git+https://github.com/huggingface/accelerate.git >/dev/null 2>&1\n",
        "!pip install opencv-contrib-python >/dev/null 2>&1\n",
        "!pip install controlnet_aux >/dev/null 2>&1\n",
        "\n"
      ],
      "metadata": {
        "id": "2_jumxegTi0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b74b67-dd97-4f1c-8324-49c1ccc6da21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 自動切断されないようにするコード { display-mode: \"form\" }\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "XesbQoV9Igeq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "28df6441-91df-456c-d563-ae6dc7322eec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ***\n",
        "\n",
        "#@title ControlNet の準備 { display-mode: \"form\" }\n",
        "\n",
        "# ワイルドカードを使ってファイルパスを検索する\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# diffusers ライブラリをインポートする\n",
        "from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler, StableDiffusionImg2ImgPipeline) # + VAEModel (0.18.0)\n",
        "from diffusers.utils import load_image\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "\n",
        "# controlnet_auxというポーズ検出のライブラリをインポートする\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "# PyTorchという深層学習フレームワークをインポートする\n",
        "import torch\n",
        "\n",
        "# PILという画像処理ライブラリをインポートする\n",
        "from PIL import Image\n",
        "\n",
        "# JPEGファイルのパスのリストを取得\n",
        "# @markdown ***ポージング学習用フォルダ***\n",
        "dir = \"/content/drive/MyDrive/StableDiffusion/ControlNet/sayapi\" #@param {type: \"string\"}\n",
        "extension = \"*.png\" #@param {type: \"string\"}\n",
        "images_path = os.path.join(dir, extension)\n",
        "# jpeg files のみを格納する\n",
        "jpeg_files = glob.glob(images_path)\n",
        "\n",
        "\n",
        "# @markdown ***\n",
        "# @markdown ***どちらかを選ぶ***\n",
        "\n",
        "# ポーズのリストを作成する\n",
        "poses = []\n",
        "\n",
        "isOpenpose = False # @param {type:\"boolean\"}\n",
        "if isOpenpose:\n",
        "    # ポーズを検出する\n",
        "    controlnet_check_path = \"lllyasviel/ControlNet\" #@param {type: \"string\"}\n",
        "    pose_detector = OpenposeDetector.from_pretrained(controlnet_check_path) # 事前学習済みのモデルを読み込む\n",
        "    for file in jpeg_files:\n",
        "        # ファイルパスから画像を読み込んでポーズを検出する\n",
        "        p = pose_detector(Image.open(file))\n",
        "        # ポーズをリストに追加する\n",
        "        poses.append(p)\n",
        "    # print(poses)\n",
        "\n",
        "# コントロールネットワークを読み込む lllyasviel/sd-controlnet-openpose\n",
        "controlnet_model_path = \"lllyasviel/sd-controlnet-openpose\"  #@param {type: \"string\"}\n",
        "\n",
        "isCanny = True # @param {type:\"boolean\"}\n",
        "if isCanny:\n",
        "    # files = os.listdir(dir + \"/\")\n",
        "    # ディレクトリ内のファイル名のリストを取得する\n",
        "    for file in jpeg_files:\n",
        "        print(file)\n",
        "        # リスト内のファイル名を順番に処理する\n",
        "        image = load_image(file)\n",
        "        image = np.array(image)\n",
        "        # 画像のデータ型をCV_8Uに変換する\n",
        "        # image = cv2.convertScaleAbs(image)\n",
        "        low_threshold, high_threshold = 100, 200\n",
        "        image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "        image = image[:, :, None]\n",
        "        image = np.concatenate([image, image, image], axis=2)\n",
        "        canny_image = Image.fromarray(image)\n",
        "        canny_image\n",
        "        # ポーズをリストに追加する\n",
        "        poses.append(canny_image)\n",
        "    print(poses)\n",
        "    controlnet_model_path = \"lllyasviel/sd-controlnet-canny\"  #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# 事前学習済みのモデルを読み込む。データ型はfloat16に指定する\n",
        "controlnet = ControlNetModel.from_pretrained(controlnet_model_path, torch_dtype=torch.float16)\n",
        "\n",
        "\n",
        "# @markdown ***\n",
        "\n",
        "# @title Model、LoRA を StableDiffusionControlNetPipeline に設定  ※LoRA の対応がまだ　{ display-mode: \"form\" }\n",
        "\n",
        "#モデル\n",
        "# @markdown 👚 Model\n",
        "model_path = \"/content/drive/MyDrive/StableDiffusion/Model/kanpiromix_v20\" #@param {type:\"string\"}\n",
        "\n",
        "device=\"cuda\"\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16,\n",
        "    # custom_pipeline=\"lpw_stable_diffusion\",\n",
        ")\n",
        "\n",
        "# VAE を読み込む\n",
        "# vae_path = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
        "# vae = VAEModel.from_pretrained(vae_path)\n",
        "\n",
        "# LoRAを追加 /content/drive/MyDrive/StableDiffusion/Lora/japaneseDollLikeness_v15.safetensors\n",
        "# lora_path = \"Kanbara/doll-likeness-series/japaneseDollLikeness_v15.safetensors\" #@param {type:\"string\"}\n",
        "# pipe.unet.load_attn_procs(lora_path)\n",
        "\n",
        "# スケジューラーを設定\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "# @@markdown ***\n",
        "\n",
        "\n",
        "# @@markdown 👙 NSFWを表示する設定\n",
        "# Disabling safety checker\n",
        "if pipe.safety_checker is not None:\n",
        "    pipe.safety_checker = lambda images, **kwargs: (images, False)\n",
        "\n",
        "# pipe.safety_checker = lambda images, **kwargs: (images, [True] * len(images))\n",
        "# isSafeNsfwOff = False  #@param {type:\"boolean\"}\n",
        "# if isSafeNsfwOff:\n",
        "#     pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "\n",
        "pipe.to(device)\n",
        "\n",
        "# @markdown ***"
      ],
      "metadata": {
        "id": "A4nXGvyCEW5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99999eee-827a-4648-f828-3d7fcb7b5cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/StableDiffusion/ControlNet/sayapi/3-sayapi.png\n",
            "/content/drive/MyDrive/StableDiffusion/ControlNet/sayapi/2-sayapi.png\n",
            "/content/drive/MyDrive/StableDiffusion/ControlNet/sayapi/1-sayapi.png\n",
            "[<PIL.Image.Image image mode=RGB size=1536x2048 at 0x7949599C2F20>, <PIL.Image.Image image mode=RGB size=1536x2048 at 0x794AD51F4550>, <PIL.Image.Image image mode=RGB size=2048x2048 at 0x794AD536FAC0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 画像生成を実行 { display-mode: \"form\" }\n",
        "\n",
        "# 必要なモジュールやライブラリをインポートする\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "i=0\n",
        "\n",
        "# 現在の日本時間を取得\n",
        "jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "\n",
        "# @markdown ***\n",
        "#txt2img出力画像の保存先\n",
        "#@markdown ***📂 出力画像を保存するフォルダ***\n",
        "save_path = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/sayapi2/\" #@param {type: \"string\"}\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "# @markdown ***\n",
        "\n",
        "#@@markdown ポジティブプロンプト\n",
        "prompt = \"(Beautiful woman wearing patterned white knit), Japanese, ((best picture quality)), (super fine), ((ultra fine)), (8K), best picture quality, dark brown long hair, ((color contacts with good color)), lips, one point tattoo, curly hair, blush, small four leaf clover necklace, (Many pierced earrings)\" #@param {type:\"string\"}\n",
        "#@@markdown ネガティブプロンプト\n",
        "negative = \"EasyNegative, (worst picture quality:2), sketch, (low quality:2), (normal quality:2),((monochrome)), (bad fingers, bad hands, missing fingers:1.3),nood, nsfw, text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, bad proportions\" #@param {type:\"string\"}\n",
        "#@markdown ***🖼 出力枚数***\n",
        "batch_count = 200 #@param {type: \"integer\"}\n",
        "#@markdown ***🦵 ステップ数***\n",
        "steps = 150 #@param {type:\"integer\"}\n",
        "#@@markdown 画像サイズ\n",
        "img_width = \"768\" # @param [512, 768, 1024, 1536]\n",
        "img_height = \"1024\" # @param [512, 768, 1024, 1536]\n",
        "#@@markdown CFG\n",
        "CFG = 7 #@param {type: \"number\"}\n",
        "#@@markdown シード（-1の時はランダム）\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "if seed is None or seed == -1:\n",
        "  inputSeed = random.randint(0, 2147483647)\n",
        "else:\n",
        "  valueSeed = seed\n",
        "\n",
        "# run stable diffusion\n",
        "images = []\n",
        "image = None\n",
        "generator = torch.Generator(device)\n",
        "poseIndex = 0\n",
        "\n",
        "for i in range(batch_count):\n",
        "\n",
        "  if seed is None or seed == -1:\n",
        "    valueSeed = inputSeed + i\n",
        "  else:\n",
        "    valueSeed = seed\n",
        "  generator.manual_seed(valueSeed)\n",
        "\n",
        "  image = pipe(\n",
        "    prompt,\n",
        "    poses[0],\n",
        "    negative_prompt=negative,\n",
        "    generator=generator,\n",
        "    num_inference_steps=steps,\n",
        "    guidance_scale=CFG,\n",
        "    width=int(img_width),\n",
        "    height=int(img_height),\n",
        "    output_type=\"pil\"\n",
        "    # max_embeddings_multiples=3,\n",
        "  )\n",
        "  poseIndex = random.randint(0, len(poses) - 1)\n",
        "\n",
        "\n",
        "  # 現在の日本時間を取得\n",
        "  jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  #出力する画像の名前を生成する\n",
        "  file_name = (jst_now.strftime(file_format)+ \"_\" + str(valueSeed))\n",
        "  image_name = file_name + f\".png\"\n",
        "\n",
        "  #画像を保存する\n",
        "  save_location = os.path.join(save_path, image_name)\n",
        "\n",
        "  # 生成された画像のリストを取得\n",
        "  images = image.images\n",
        "\n",
        "  # 生成された画像の数を取得\n",
        "  num_images = len(images)\n",
        "\n",
        "  # 生成された画像を順番に保存\n",
        "  for i in range(num_images):\n",
        "    # 画像を取り出す\n",
        "    image = images[i]\n",
        "\n",
        "    # @markdown ***\n",
        "    #@markdown ***✎ メタデータの書き込み***\n",
        "    save_metadata = True #@param {type: \"boolean\"}\n",
        "    if save_metadata:\n",
        "      metadata = PngInfo()\n",
        "      metadata.add_text(\"prompt\",(prompt))\n",
        "      metadata.add_text(\"negative\",(negative))\n",
        "      metadata.add_text(\"steps\",(str(steps)))\n",
        "      metadata.add_text(\"CFG\",(str(CFG)))\n",
        "      metadata.add_text(\"width\",(str(img_width)))\n",
        "      metadata.add_text(\"height\",(str(img_height)))\n",
        "      metadata.add_text(\"seed\",str((valueSeed)))\n",
        "      image.save(save_location, pnginfo=metadata)\n",
        "\n",
        "    # dst = Image.new('RGB', (image.shape[1], image.shape[0]))\n",
        "    # dst.paste(output, (0, 0))\n",
        "\n",
        "    # # 画像保存。googleドライブの出力ディレクトリに、年月日時分秒からなるファイル名で保存\n",
        "    # filename = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y%m%d%H%M%S')\n",
        "    # dst.save(out_dir+'/'+filename+'.png')\n",
        "\n",
        "    # dst # 画像表示\n",
        "\n",
        "    # @markdown ***\n"
      ],
      "metadata": {
        "id": "tJ9NqU4F8UpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIVx0EDv0Z7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 画像のメタデータを出力\n",
        "\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "#@markdown **保存した画像のパス**\n",
        "file_dir = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/\"  #@param {type: \"string\"}\n",
        "file_name = \"20230707_235255_101570535.png\" #@param {type: \"string\"}\n",
        "file_path = os.path.join(file_dir, file_name)\n",
        "img = Image.open(file_path)\n",
        "\n",
        "print(\"Prompt: \",img.text[\"prompt\"])\n",
        "print(\"Negative Prompt: \",img.text[\"negative\"])\n",
        "print(\"Scheduler: \", img.text[\"scheduler\"])\n",
        "print(\"Steps: \",img.text[\"steps\"])\n",
        "print(\"CFG: \",img.text[\"CFG\"])\n",
        "print(\"Width: \",img.text[\"width\"])\n",
        "print(\"Height: \",img.text[\"height\"])\n",
        "print(\"Seed: \",img.text[\"seed\"])\n",
        "\n",
        "try:\n",
        "  print(\"Upscaling ratio; \",img.text[\"upscaling ratio\"])\n",
        "  print(\"Up steps: \",img.text[\"up steps\"])\n",
        "  print(\"Denoising strength: \",img.text[\"denoising strength\"])\n",
        "except:\n",
        "  print(\"Hires.fix was OFF.\")\n",
        "\n",
        "# %%writefile output.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}