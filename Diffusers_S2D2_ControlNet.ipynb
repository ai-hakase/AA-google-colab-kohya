{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2_ControlNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWXJo4TqbdN"
      },
      "source": [
        "## **Diffusers ライブラリを用いて、画像を生成するスクリプト。**\n",
        "参考：<br>\n",
        "[日本語](https://blog.shikoan.com/controlnet_lora/#ControlNet%EF%BC%88%E3%83%9D%E3%83%BC%E3%82%BA%EF%BC%89%E3%82%92%E4%BD%BF%E3%81%86)<br>\n",
        "[英語](https://huggingface.co/blog/controlnet)<br>\n",
        "[Github - AA-google-colab-kohya](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveに接続, ライブラリの追加 { display-mode: \"form\" }\n",
        "\n",
        "# Driveに接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ライブラリの追加\n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion >/dev/null 2>&1\n",
        "!pip install --upgrade xformers git+https://github.com/huggingface/accelerate.git >/dev/null 2>&1\n",
        "!pip install opencv-contrib-python >/dev/null 2>&1\n",
        "!pip install controlnet_aux >/dev/null 2>&1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_jumxegTi0E",
        "outputId": "97669c4d-dac7-47ff-962a-ef0d755cbdf8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 自動切断されないようにするコード { display-mode: \"form\" }\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "XesbQoV9Igeq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a8014ebb-eee3-484e-f098-ab6b31a38a0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 最新版（0.18.0）\n",
        "# !pip install git+https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "id": "c6lS2zv43RZS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ライブラリをインポート + S2D2 / Embeddingsの準備 { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!git clone https://github.com/keisuke-okb/S2D2 &> /dev/null\n",
        "\n",
        "%cd ./S2D2\n",
        "!git pull\n",
        "!touch __init__.py\n",
        "!pip install -r requirements.txt >/dev/null 2>&1\n",
        "\n",
        "\n",
        "# 各ライブラリをインポート\n",
        "import s2d2\n",
        "\n",
        "# diffusers ライブラリをインポートする\n",
        "import diffusers\n",
        "from diffusers import (StableDiffusionPipeline,StableDiffusionImg2ImgPipeline)\n",
        "\n",
        "# PyTorchという深層学習フレームワークをインポートする\n",
        "import torch\n",
        "\n",
        "\n",
        "class StableDiffusionImageGeneratorMod(s2d2.StableDiffusionImageGenerator):\n",
        "  def __init__(self, sd_safetensor_path: str, device: str=\"cuda\", dtype: torch.dtype=torch.float16, controlnet=None, vae=None):\n",
        "    self.device = torch.device(device)\n",
        "    self.controlnet = controlnet # ここで属性を作る\n",
        "    self.vae = vae\n",
        "    self.pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      sd_safetensor_path,\n",
        "      torch_dtype=dtype,\n",
        "      custom_pipeline=\"lpw_stable_diffusion\"\n",
        "    ).to(device)\n",
        "    self.pipe_i2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "      sd_safetensor_path,\n",
        "      torch_dtype=dtype,\n",
        "      custom_pipeline=\"lpw_stable_diffusion\"\n",
        "    ).to(device)\n",
        "    self.pipe.safety_checker = None\n",
        "    self.pipe_i2i.safety_checker = None\n",
        "    return\n",
        "\n",
        "  def load_embeddings(self, safetensors_path: str, fileName: str, token: str):\n",
        "    if token != \"\":\n",
        "      self.pipe.load_textual_inversion(safetensors_path, weight_name=fileName, token=token)\n",
        "      self.pipe_i2i.load_textual_inversion(safetensors_path, weight_name=fileName, token=token)\n",
        "    else:\n",
        "      self.pipe.load_textual_inversion(safetensors_path, weight_name=fileName)\n",
        "      self.pipe_i2i.load_textual_inversion(safetensors_path, weight_name=fileName)\n",
        "    return\n",
        "\n",
        "  %cd /content/\n"
      ],
      "metadata": {
        "id": "BFwHNs_9xLCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ControlNet の準備 { display-mode: \"code\" }\n",
        "\n",
        "# ワイルドカードを使ってファイルパスを検索する\n",
        "import glob\n",
        "\n",
        "# diffusers ライブラリをインポートする\n",
        "from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler, StableDiffusionImg2ImgPipeline) # VAEModel\n",
        "from diffusers.utils import numpy_to_pil\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "\n",
        "# controlnet_auxというポーズ検出のライブラリをインポートする\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "# PyTorchという深層学習フレームワークをインポートする\n",
        "import torch\n",
        "\n",
        "# PILという画像処理ライブラリをインポートする\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# JPEGファイルのパスのリストを取得\n",
        "dir = \"/content/drive/MyDrive/StableDiffusion/ControlNet/spread_legs\" #@param {type: \"string\"}\n",
        "wildcard = \"/*.\"\n",
        "extension = \"png\" #@param {type: \"string\"}\n",
        "images_path = os.path.join(dir, wildcard, extension)\n",
        "jpeg_files = glob.glob(images_path)\n",
        "\n",
        "# ポーズを検出する\n",
        "controlnet_model_path = \"lllyasviel/ControlNet\"\n",
        "pose_detector = OpenposeDetector.from_pretrained(controlnet_model_path) # 事前学習済みのモデルを読み込む\n",
        "poses = [] # ポーズのリストを作成する\n",
        "for file in jpeg_files: # リストの要素を繰り返し処理する\n",
        "    p = pose_detector(Image.open(file)) # ファイルパスから画像を読み込んでポーズを検出する\n",
        "    poses.append(p) # ポーズをリストに追加する\n",
        "\n",
        "# コントロールネットワークを読み込む\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/sd-controlnet-openpose\", torch_dtype=torch.float16) # 事前学習済みのモデルを読み込む。データ型はfloat16に指定する\n",
        "\n"
      ],
      "metadata": {
        "id": "6CJX5oAxWWEp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model、LoRA を StableDiffusionImageGeneratorMod に設定 { display-mode: \"form\" }\n",
        "\n",
        "#モデル\n",
        "# @markdown *Model ------------------------**\n",
        "model_path = \"/content/drive/MyDrive/StableDiffusion/Model/chilled_remix_v2\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# VAE を読み込む\n",
        "# vae_path = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
        "# vae = VAEModel.from_pretrained(vae_path)\n",
        "\n",
        "generator = StableDiffusionImageGeneratorMod(\n",
        "  model_path,\n",
        "  # vae=vae,\n",
        "  controlnet=controlnet,\n",
        "  device=\"cuda\"\n",
        ")\n",
        "\n",
        "# @markdown **LoRA1 ------------------------**\n",
        "LoRA_USE = True #@param {type:\"boolean\"}\n",
        "if LoRA_USE == True:\n",
        "  LoRA=\"/content/drive/MyDrive/StableDiffusion/Lora/flat2.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha = -1.0 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA, alpha=LoRA_alpha)\n",
        "\n",
        "# @markdown **LoRA2 ------------------------**\n",
        "LoRA_USE_2= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/StableDiffusion/Lora/koreanDollLikeness_v20.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_2 = 0.6 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "# @markdown **LoRA3 ------------------------**\n",
        "LoRA_USE_3= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/StableDiffusion/Lora/trueBuruma_v26red.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_3 = 0.1 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "# @markdown **LoRA4 ------------------------**\n",
        "LoRA_USE_4= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_4 = 0.5 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "# @title Embeddings を StableDiffusionImageGeneratorMod に設定 　 { display-mode: \"form\" }\n",
        "\n",
        "#@markdown **Embeddings 1**\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path = \"/content/drive/MyDrive/StableDiffusion/embeddings/EasyNegative.safetensors\" #@param {type:\"string\"}\n",
        "  file_name = \"EasyNegative.safetensors\" #@param {type:\"string\"}\n",
        "  #@markdown ***トリガーワード（EasyNegativeなど）***\n",
        "  token = \"EasyNegative\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path, file_name, token)\n",
        "\n",
        "#@markdown **Embeddings 2**\n",
        "embeddings_USE_2 = False #@param {type:\"boolean\"}\n",
        "if embeddings_USE_2 == True:\n",
        "  safetensors_path_2 = \"/content/drive/MyDrive/StableDiffusion/embeddings/ulzzang-6500-v1.1.pt\" #@param {type:\"string\"}\n",
        "  file_name_2 = \"ulzzang-6500-v1.1.pt\" #@param {type:\"string\"}\n",
        "  token_2 = \"ulzzang-6500-v1.1\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_2, file_name_2, token_2)\n",
        "\n",
        "#@markdown **Embeddings 3**\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path_3 = \"/content/drive/MyDrive/StableDiffusion/embeddings/pureerosface_v1.pt\" #@param {type:\"string\"}\n",
        "  file_name_3 = \"pureerosface_v1.pt\" #@param {type:\"string\"}\n",
        "  token_3 = \"pureerosface_v1\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_3, file_name_3, token_3)\n",
        "\n",
        "#@markdown **Embeddings 4**\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path_4 = \"/content/drive/MyDrive/StableDiffusion/embeddings/ng_deepnegative_v1_75t.pt\" #@param {type:\"string\"}\n",
        "  file_name_4 = \"ng_deepnegative_v1_75t.pt\" #@param {type:\"string\"}\n",
        "  token_4 = \"ng_deepnegative_v1_75t\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_4, file_name_4, token_4)\n",
        "\n",
        "#@markdown **Embeddings 5**\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path_5 = \"/content/drive/MyDrive/StableDiffusion/embeddings/negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "  file_name_5 = \"negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "  token_5 = \"negative_hand-neg\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_5, file_name_5, token_5)\n",
        "\n"
      ],
      "metadata": {
        "id": "tJ9NqU4F8UpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYM1Dv3QeR08"
      },
      "outputs": [],
      "source": [
        "# @title 画像を生成  { display-mode: \"code\" }\n",
        "\n",
        "# 必要なモジュールやライブラリをインポートする\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "# ファイル名に使う日付と時刻のフォーマットを定義する\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "i=0\n",
        "\n",
        "# 現在の日本時間を取得\n",
        "jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "#txt2img出力画像の保存先\n",
        "#@markdown 出力画像を保存するフォルダ\n",
        "save_path = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/test2/\" #@param {type: \"string\"}\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "\n",
        "#@markdown ポジティブプロンプト\n",
        "prompt = \"Beautiful girl,(See-through clothes very wet with water,sitting,very wet body:1.3),(red bloomers,red gym clothes, under size clothes),(camel toe, exposure pants:1.3 ),short brown hair,((super detail)), photo realistic, 8K UHD,(best quality:1. 2), high resolution, fine details, fine textures, facial expression, high details, delicate and beautiful eyes, perfectly proportioned face, light particles, clear_image, high resolution, high quality textures and shadows, realistic and beautiful face with big eyes, blush, glossy lips and perfect proportions, depth of field, lens flare, ray tracing, perspective,glossy skin, (smiling, shy),low angle,shiny hands, nfsw,see through nipples, see through pants\" #@param {type:\"string\"}\n",
        "#@markdown ネガティブプロンプト\n",
        "negative = \"EasyNegative, painting, sketch, (worst picture quality:2), (low quality:2), (normal quality:2), bad feet, lowres, ((monochrome)),(ng_deepnegative_v1_75t),(negative_hand-neg:1.2),skin blemishes, acne, skin blemishes, bad anatomy, (bad fingers, bad hands, missing fingers:1.3), text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, crossed eyes, very low resolution, bad proportions\" #@param {type:\"string\"}\n",
        "#@markdown 出力枚数\n",
        "batch_count = 20 #@param {type: \"integer\"}\n",
        "#@markdown ステップ数\n",
        "steps = 20 #@param {type:\"integer\"}\n",
        "#@markdown 画像サイズ\n",
        "img_width = \"512\" # @param [512, 768, 1024, 1536]\n",
        "img_height = \"768\" # @param [512, 768, 1024, 1536]\n",
        "#@markdown CFG\n",
        "CFG = 7 #@param {type: \"number\"}\n",
        "#@markdown スケジューラ(サンプラー)\n",
        "scheduler=\"dpm++_2m_karras\" #@param [\"unipc\",\"euler_a\",\"euler\",\"ddim\",\"ddpm\",\"deis\",\"dpm2\",\"dpm++_2s\",\"dpm++_2m\",\"dpm++_2m_karras\",\"dpm++_sde\",\"dpm++_sde_karras\",\"heun\",\"heun_karras\",\"lms\",\"lms_karras\",\"pndm\",\"dpm++_2m_karras\"]\n",
        "#@markdown シード（-1の時はランダム）\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "if seed is None or seed == -1:\n",
        "  inputSeed = random.randint(0, 2147483647)\n",
        "else:\n",
        "  valueSeed = seed\n",
        "\n",
        "#@markdown Hires.fix の有効化\n",
        "hires_fix = True #@param {type: \"boolean\"}\n",
        "enhance_steps = 2 if hires_fix else 1\n",
        "#@markdown 解像度倍率(乗算後、最も近い8の倍数のサイズとなる)\n",
        "upscaling_ratio = 2 #@param {type: \"number\"}\n",
        "#@markdown アップスケールステップ数\n",
        "up_steps = 20 #@param {type: \"integer\"}\n",
        "#@markdown denoising strength（小さいほど元画像を尊重） （0.5～0.7）が推奨\n",
        "denoising_strength = 0.60 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "for i in range(batch_count):\n",
        "  if seed is None or seed == -1:valueSeed = inputSeed + i\n",
        "  image = generator.diffusion_enhance(\n",
        "    prompt,\n",
        "    negative,\n",
        "    scheduler_name=scheduler,\n",
        "    num_inference_steps=steps,\n",
        "    num_inference_steps_enhance=up_steps,\n",
        "    guidance_scale=CFG,\n",
        "    width=img_width,\n",
        "    height=img_height,\n",
        "    seed=valueSeed,\n",
        "    upscale_target=\"latent\",\n",
        "    interpolate_mode=\"bicubic\",\n",
        "    antialias=True,\n",
        "    # diffusion_enhance=True,\n",
        "    upscale_by=upscaling_ratio,\n",
        "    enhance_steps=enhance_steps,\n",
        "    denoising_strength=denoising_strength,\n",
        "    output_type=\"pil\",\n",
        "    decode_factor=0.15,\n",
        "    decode_factor_final=0.18215\n",
        "  )\n",
        "\n",
        "  # 現在の日本時間を取得\n",
        "  jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  #出力する画像の名前を生成する\n",
        "  file_name = (jst_now.strftime(file_format)+ \"_\" + str(valueSeed))\n",
        "  image_name = file_name + f\".png\"\n",
        "\n",
        "  #画像を保存する\n",
        "  save_location = os.path.join(save_path, image_name)\n",
        "\n",
        "  #@markdown **メタデータの書き込み**\n",
        "  save_metadata = True #@param {type: \"boolean\"}\n",
        "  if save_metadata:\n",
        "    metadata = PngInfo()\n",
        "    metadata.add_text(\"prompt\",(prompt))\n",
        "    metadata.add_text(\"negative\",(negative))\n",
        "    metadata.add_text(\"scheduler\",(scheduler))\n",
        "    metadata.add_text(\"steps\",(str(steps)))\n",
        "    metadata.add_text(\"CFG\",(str(CFG)))\n",
        "    metadata.add_text(\"width\",(str(img_width)))\n",
        "    metadata.add_text(\"height\",(str(img_height)))\n",
        "    metadata.add_text(\"seed\",str((valueSeed)))\n",
        "  if hires_fix:\n",
        "    metadata.add_text(\"upscaling ratio\",str((upscaling_ratio)))\n",
        "    metadata.add_text(\"up steps\",str((up_steps)))\n",
        "    metadata.add_text(\"denoising strength\",str((denoising_strength)))\n",
        "    image.save(save_location, pnginfo=metadata)\n",
        "  else:\n",
        "    image.save(save_location)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIVx0EDv0Z7"
      },
      "outputs": [],
      "source": [
        "# @title 画像のメタデータを出力\n",
        "\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "#@markdown **保存した画像のパス**\n",
        "file_dir = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/test2/\"  #@param {type: \"string\"}\n",
        "file_name = \"20230710_170302_1067497271.png\" #@param {type: \"string\"}\n",
        "file_path = os.path.join(save_path, file_name)\n",
        "img = Image.open(file_path)\n",
        "\n",
        "print(\"Prompt: \",img.text[\"prompt\"])\n",
        "print(\"Negative Prompt: \",img.text[\"negative\"])\n",
        "print(\"Scheduler: \", img.text[\"scheduler\"])\n",
        "print(\"Steps: \",img.text[\"steps\"])\n",
        "print(\"CFG: \",img.text[\"CFG\"])\n",
        "print(\"Width: \",img.text[\"width\"])\n",
        "print(\"Height: \",img.text[\"height\"])\n",
        "print(\"Seed: \",img.text[\"seed\"])\n",
        "\n",
        "try:\n",
        "  print(\"Upscaling ratio; \",img.text[\"upscaling ratio\"])\n",
        "  print(\"Up steps: \",img.text[\"up steps\"])\n",
        "  print(\"Denoising strength: \",img.text[\"denoising strength\"])\n",
        "except:\n",
        "  print(\"Hires.fix was OFF.\")\n",
        "\n",
        "# %%writefile output.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title メモ\n",
        "# ######################################################################################\n",
        "\n",
        "\n",
        "# # 安定拡散法のパイプラインを作成する。前学習済みのモデルとコントロールネットワークを読み込む。\n",
        "# pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "#         \"sinkinai/Beautiful-Realistic-Asians-v5\", controlnet=controlnet, torch_dtype=torch.float16\n",
        "#     )\n",
        "\n",
        "# # スケジューラーを設定。UniPCMultistepScheduler を作成し、既存のスケジューラーの設定を引き継ぐ\n",
        "# pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# # セーフティチェッカーを無効化する。　画像とその他の引数を受け取り、画像とFalseのリストを返す\n",
        "# if pipe.safety_checker is not None: # セーフティチェッカーがNoneでない場合\n",
        "#     pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "\n",
        "# # パイプラインをGPUに移動させる\n",
        "# pipe.to(device)\n",
        "\n",
        "#@title 安定拡散法を実行する { display-mode: \"code\" }\n",
        "\n",
        "# # 各ライブラリをインポート\n",
        "# import os\n",
        "# import datetime\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# images = [] # 画像のリストを作成する\n",
        "# generator = torch.Generator(device) # 乱数生成器というオブジェクトを作成し、GPUに移動させる\n",
        "# prompt = \"1girl, masterpiece, best quality, extremely detailed, 4K, illustration\"\n",
        "# negative_prompt = \"low quality, worst quality, bad fingers, bad face, extra arms, extra legs\"\n",
        "\n",
        "# for i in range(3): # 3回繰り返す\n",
        "#   for j in range(4): # 4回繰り返す\n",
        "#       # 乱数シードを設定\n",
        "#       generator.manual_seed(i+1024)\n",
        "#       # パイプラインを実行して画像を生成\n",
        "#       image = pipe(prompt, poses[j], negative_prompt=negative_prompt, generator=generator,\n",
        "#                   num_inference_steps=10, output_type=\"numpy\", width=512, height=704).images[0]\n",
        "#       images.append(image) # 画像をリストに追加\n",
        "\n",
        "# # 画像をnumpy配列に変換してスケール\n",
        "# images = (np.stack(images, axis=0) * 255.0).astype(np.uint8)\n",
        "\n",
        "# n = len(images) # 画像の枚数を取得\n",
        "\n",
        "# # 画像の枚数分繰り返す\n",
        "# for i in range(n):\n",
        "#   # PILイメージに変換\n",
        "#   with Image.fromarray(images[i]) as img:\n",
        "#       img.save(f\"result_{i}.jpg\") # result_i.jpgという名前で保存\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nC3CpWkerkfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}