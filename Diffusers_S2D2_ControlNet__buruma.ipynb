{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2_ControlNet__buruma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDWXJo4TqbdN"
      },
      "source": [
        "## **Diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç”¨ã„ã¦ã€ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚**\n",
        "å‚è€ƒ ï¼š\n",
        "[æ—¥æœ¬èª](https://blog.shikoan.com/controlnet_lora/#ControlNet%EF%BC%88%E3%83%9D%E3%83%BC%E3%82%BA%EF%BC%89%E3%82%92%E4%BD%BF%E3%81%86)  ,\n",
        "[è‹±èª](https://huggingface.co/blog/controlnet) ,\n",
        "[Github - AA-google-colab-kohya](https://github.com/koya-jp/AA-google-colab-kohya/blob/master/Diffusers_S2D2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveã«æ¥ç¶š, ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ  { display-mode: \"form\" }\n",
        "\n",
        "# Driveã«æ¥ç¶š\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ \n",
        "!pip install --upgrade diffusers==0.17.1 transformers accelerate scipy ftfy safetensors txt2img >/dev/null 2>&1\n",
        "!pip install k-diffusion >/dev/null 2>&1\n",
        "!pip install --upgrade xformers git+https://github.com/huggingface/accelerate.git >/dev/null 2>&1\n",
        "!pip install opencv-contrib-python >/dev/null 2>&1\n",
        "!pip install controlnet_aux >/dev/null 2>&1\n",
        "\n",
        "# æœ€æ–°ç‰ˆï¼ˆ0.18.0ï¼‰\n",
        "# !pip install git+https://github.com/huggingface/diffusers"
      ],
      "metadata": {
        "id": "2_jumxegTi0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title è‡ªå‹•åˆ‡æ–­ã•ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹ã‚³ãƒ¼ãƒ‰ { display-mode: \"form\" }\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "XesbQoV9Igeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ + S2D2 / Embeddingsã®æº–å‚™ { display-mode: \"form\" }\n",
        "%cd /content\n",
        "!git clone https://github.com/keisuke-okb/S2D2 &> /dev/null\n",
        "\n",
        "%cd ./S2D2\n",
        "!git pull\n",
        "!touch __init__.py\n",
        "!pip install -r requirements.txt >/dev/null 2>&1\n",
        "\n",
        "\n",
        "# å„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import s2d2\n",
        "\n",
        "# diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import diffusers\n",
        "from diffusers import (StableDiffusionPipeline,StableDiffusionImg2ImgPipeline)\n",
        "\n",
        "# PyTorchã¨ã„ã†æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import torch\n",
        "\n",
        "\n",
        "class StableDiffusionImageGeneratorMod(s2d2.StableDiffusionImageGenerator):\n",
        "  def __init__(self, sd_safetensor_path: str, device: str=\"cuda\", dtype: torch.dtype=torch.float16, controlnet=None, vae=None):\n",
        "    self.device = torch.device(device)\n",
        "    self.controlnet = controlnet # ã“ã“ã§å±æ€§ã‚’ä½œã‚‹\n",
        "    self.vae = vae\n",
        "    self.pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      sd_safetensor_path,\n",
        "      torch_dtype=dtype,\n",
        "      custom_pipeline=\"lpw_stable_diffusion\"\n",
        "    ).to(device)\n",
        "    self.pipe_i2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "      sd_safetensor_path,\n",
        "      torch_dtype=dtype,\n",
        "      custom_pipeline=\"lpw_stable_diffusion\"\n",
        "    ).to(device)\n",
        "    self.pipe.safety_checker = None\n",
        "    self.pipe_i2i.safety_checker = None\n",
        "    return\n",
        "\n",
        "  def load_embeddings(self, safetensors_path: str, fileName: str, token: str):\n",
        "    if token != \"\":\n",
        "      self.pipe.load_textual_inversion(safetensors_path, weight_name=fileName, token=token)\n",
        "      self.pipe_i2i.load_textual_inversion(safetensors_path, weight_name=fileName, token=token)\n",
        "    else:\n",
        "      self.pipe.load_textual_inversion(safetensors_path, weight_name=fileName)\n",
        "      self.pipe_i2i.load_textual_inversion(safetensors_path, weight_name=fileName)\n",
        "    return\n",
        "\n",
        "  %cd /content/\n"
      ],
      "metadata": {
        "id": "BFwHNs_9xLCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ControlNet ã®æº–å‚™ { display-mode: \"form\" }\n",
        "\n",
        "# ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ¤œç´¢ã™ã‚‹\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from diffusers import (StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler, StableDiffusionImg2ImgPipeline) # + VAEModel (0.18.0)\n",
        "from diffusers.utils import numpy_to_pil\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "\n",
        "# controlnet_auxã¨ã„ã†ãƒãƒ¼ã‚ºæ¤œå‡ºã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from controlnet_aux import OpenposeDetector\n",
        "\n",
        "# PyTorchã¨ã„ã†æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import torch\n",
        "\n",
        "# PILã¨ã„ã†ç”»åƒå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# JPEGãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "# @markdown ***ãƒãƒ¼ã‚¸ãƒ³ã‚°å­¦ç¿’ç”¨ãƒ•ã‚©ãƒ«ãƒ€***\n",
        "dir = \"/content/drive/MyDrive/StableDiffusion/ControlNet/spread_legs\" #@param {type: \"string\"}\n",
        "wildcard = \"/*.\"\n",
        "extension = \"png\" #@param {type: \"string\"}\n",
        "images_path = os.path.join(dir, wildcard, extension)\n",
        "jpeg_files = glob.glob(images_path)\n",
        "\n",
        "# ãƒãƒ¼ã‚ºã‚’æ¤œå‡ºã™ã‚‹\n",
        "controlnet_check_path = \"lllyasviel/ControlNet\" #@param {type: \"string\"}\n",
        "pose_detector = OpenposeDetector.from_pretrained(controlnet_check_path) # äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
        "# ãƒãƒ¼ã‚ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹\n",
        "poses = []\n",
        "for file in jpeg_files:\n",
        "    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ¼ã‚ºã‚’æ¤œå‡ºã™ã‚‹\n",
        "    p = pose_detector(Image.open(file))\n",
        "    # ãƒãƒ¼ã‚ºã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹\n",
        "    poses.append(p)\n",
        "\n",
        "# ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’èª­ã¿è¾¼ã‚€\n",
        "controlnet_model_path = \"lllyasviel/sd-controlnet-openpose\"  #@param {type: \"string\"}\n",
        "# äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ‡ãƒ¼ã‚¿å‹ã¯float16ã«æŒ‡å®šã™ã‚‹\n",
        "controlnet = ControlNetModel.from_pretrained(controlnet_model_path, torch_dtype=torch.float16)\n",
        "\n"
      ],
      "metadata": {
        "id": "6CJX5oAxWWEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Modelã€LoRA ã‚’ StableDiffusionImageGeneratorMod ã«è¨­å®š { display-mode: \"form\" }\n",
        "\n",
        "#ãƒ¢ãƒ‡ãƒ«\n",
        "# @markdown **ğŸ‘š Model ########################################################################**\n",
        "model_path = \"/content/drive/MyDrive/StableDiffusion/Model/chilled_remix_v2\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# VAE ã‚’èª­ã¿è¾¼ã‚€\n",
        "# vae_path = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
        "# vae = VAEModel.from_pretrained(vae_path)\n",
        "\n",
        "generator = StableDiffusionImageGeneratorMod(\n",
        "  model_path,\n",
        "  # vae=vae,\n",
        "  controlnet=controlnet,\n",
        "  device=\"cuda\"\n",
        ")\n",
        "\n",
        "# @markdown **<br>ğŸ™ LoRA ########################################################################**\n",
        "LoRA_USE_1 = True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_1 == True:\n",
        "  LoRA_1=\"/content/drive/MyDrive/StableDiffusion/Lora/flat2.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_1 = -1.0 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_1, alpha=LoRA_alpha_1)\n",
        "\n",
        "LoRA_USE_2= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_2== True:\n",
        "  LoRA_2=\"/content/drive/MyDrive/StableDiffusion/Lora/koreanDollLikeness_v20.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_2 = 0.6 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_2, alpha=LoRA_alpha_2)\n",
        "\n",
        "LoRA_USE_3= True #@param {type:\"boolean\"}\n",
        "if LoRA_USE_3== True:\n",
        "  LoRA_3=\"/content/drive/MyDrive/StableDiffusion/Lora/trueBuruma_v26red.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_3 = 0.1 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_3, alpha=LoRA_alpha_3)\n",
        "\n",
        "LoRA_USE_4= False #@param {type:\"boolean\"}\n",
        "if LoRA_USE_4== True:\n",
        "  LoRA_4=\"/content/drive/MyDrive/Lora/EkunePOVFellatioV2.safetensors\" #@param {type:\"string\"}\n",
        "  LoRA_alpha_4 = 0.5 #@param {type:\"number\"}\n",
        "  generator.load_lora(LoRA_4, alpha=LoRA_alpha_4)\n",
        "\n",
        "\n",
        "#@markdown **<br>ğŸ‘¾ Embeddings ########################################################################**\n",
        "embeddings_USE_1 = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE_1 == True:\n",
        "  safetensors_path_1 = \"/content/drive/MyDrive/StableDiffusion/embeddings/EasyNegative.safetensors\" #@param {type:\"string\"}\n",
        "  file_name_1 = \"EasyNegative.safetensors\" #@param {type:\"string\"}\n",
        "  token_1 = \"EasyNegative\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_1, file_name_1, token_1)\n",
        "\n",
        "embeddings_USE_2 = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE_2 == True:\n",
        "  safetensors_path_2 = \"/content/drive/MyDrive/StableDiffusion/embeddings/negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "  file_name_2 = \"negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "  token_2 = \"negative_hand-neg\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_2, file_name_2, token_2)\n",
        "\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path_3 = \"/content/drive/MyDrive/StableDiffusion/embeddings/pureerosface_v1.pt\" #@param {type:\"string\"}\n",
        "  file_name_3 = \"pureerosface_v1.pt\" #@param {type:\"string\"}\n",
        "  token_3 = \"pureerosface_v1\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_3, file_name_3, token_3)\n",
        "\n",
        "embeddings_USE = True #@param {type:\"boolean\"}\n",
        "if embeddings_USE == True:\n",
        "  safetensors_path_4 = \"/content/drive/MyDrive/StableDiffusion/embeddings/ng_deepnegative_v1_75t.pt\" #@param {type:\"string\"}\n",
        "  file_name_4 = \"ng_deepnegative_v1_75t.pt\" #@param {type:\"string\"}\n",
        "  token_4 = \"ng_deepnegative_v1_75t\" #@param {type:\"string\"}\n",
        "  generator.load_embeddings(safetensors_path_4, file_name_4, token_4)\n",
        "\n",
        "# embeddings_USE = True #@param {type:\"boolean\"}\n",
        "# if embeddings_USE == True:\n",
        "#   safetensors_path_5 = \"/content/drive/MyDrive/StableDiffusion/embeddings/negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "#   file_name_5 = \"negative_hand-neg.pt\" #@param {type:\"string\"}\n",
        "#   token_5 = \"negative_hand-neg\" #@param {type:\"string\"}\n",
        "#   generator.load_embeddings(safetensors_path_5, file_name_5, token_5)\n",
        "\n"
      ],
      "metadata": {
        "id": "tJ9NqU4F8UpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYM1Dv3QeR08"
      },
      "outputs": [],
      "source": [
        "# @title ç”»åƒã‚’ç”Ÿæˆ  { display-mode: \"form\" }\n",
        "\n",
        "# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹\n",
        "import os\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ã†æ—¥ä»˜ã¨æ™‚åˆ»ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã™ã‚‹\n",
        "file_format = \"%Y%m%d_%H%M%S\"\n",
        "i=0\n",
        "\n",
        "# ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—\n",
        "jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "#txt2imgå‡ºåŠ›ç”»åƒã®ä¿å­˜å…ˆ\n",
        "#@markdown ***å‡ºåŠ›ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€***\n",
        "save_path = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/buruma/\" #@param {type: \"string\"}\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "\n",
        "#@@markdown ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "prompt = \"Beautiful girl,(See-through clothes very wet with water,sitting,very wet body:1.3),(red bloomers,red gym clothes, under size clothes),(camel toe, exposure pants:1.3 ),short brown hair,((super detail)), photo realistic, 8K UHD,(best quality:1. 2), high resolution, fine details, fine textures, facial expression, high details, delicate and beautiful eyes, perfectly proportioned face, light particles, clear_image, high resolution, high quality textures and shadows, realistic and beautiful face with big eyes, blush, glossy lips and perfect proportions, depth of field, lens flare, ray tracing, perspective,glossy skin, (smiling, shy),low angle,shiny hands, nfsw,see through nipples, see through pants\" #@param {type:\"string\"}\n",
        "#@@markdown ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
        "negative = \"EasyNegative, painting, sketch, (worst picture quality:2), (low quality:2), (normal quality:2), bad feet, lowres, ((monochrome)),(ng_deepnegative_v1_75t),(negative_hand-neg:1.2),skin blemishes, acne, skin blemishes, bad anatomy, (bad fingers, bad hands, missing fingers:1.3), text, error, missing fingers, extra fingers, few digits, crop, worst picture quality, jpeg image, signature, watermark, Username, blurred, bad feet, (mutation, deformity:1. 3), extra limbs, fused fingers, long neck, crossed eyes, very low resolution, bad proportions\" #@param {type:\"string\"}\n",
        "#@markdown ***å‡ºåŠ›æšæ•°***\n",
        "batch_count = 200 #@param {type: \"integer\"}\n",
        "#@markdown ***ã‚¹ãƒ†ãƒƒãƒ—æ•°***\n",
        "steps = 30 #@param {type:\"integer\"}\n",
        "#@@markdown ç”»åƒã‚µã‚¤ã‚º\n",
        "img_width = \"512\" # @param [512, 768, 1024, 1536]\n",
        "img_height = \"768\" # @param [512, 768, 1024, 1536]\n",
        "#@@markdown CFG\n",
        "CFG = 7 #@param {type: \"number\"}\n",
        "#@markdown ***ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©(ã‚µãƒ³ãƒ—ãƒ©ãƒ¼)***\n",
        "scheduler=\"dpm++_2m_karras\" #@param [\"unipc\",\"euler_a\",\"euler\",\"ddim\",\"ddpm\",\"deis\",\"dpm2\",\"dpm++_2s\",\"dpm++_2m\",\"dpm++_2m_karras\",\"dpm++_sde\",\"dpm++_sde_karras\",\"heun\",\"heun_karras\",\"lms\",\"lms_karras\",\"pndm\",\"dpm++_2m_karras\"]\n",
        "#@@markdown ã‚·ãƒ¼ãƒ‰ï¼ˆ-1ã®æ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼‰\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "if seed is None or seed == -1:\n",
        "  inputSeed = random.randint(0, 2147483647)\n",
        "else:\n",
        "  valueSeed = seed\n",
        "\n",
        "#@markdown ***Hires.fix ã®æœ‰åŠ¹åŒ–***\n",
        "hires_fix = True #@param {type: \"boolean\"}\n",
        "enhance_steps = 2 if hires_fix else 1\n",
        "#@markdown ***è§£åƒåº¦å€ç‡(ä¹—ç®—å¾Œã€æœ€ã‚‚è¿‘ã„8ã®å€æ•°ã®ã‚µã‚¤ã‚ºã¨ãªã‚‹)***\n",
        "upscaling_ratio = 2 #@param {type: \"number\"}\n",
        "#@markdown ***ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒ«ã‚¹ãƒ†ãƒƒãƒ—æ•°***\n",
        "up_steps = 20 #@param {type: \"integer\"}\n",
        "#@markdown ***å°ã•ã„ã»ã©å…ƒç”»åƒã‚’å°Šé‡ï¼‰ ï¼ˆ0.5ï½0.7ï¼‰ãŒæ¨å¥¨***\n",
        "denoising_strength = 0.60 #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "for i in range(batch_count):\n",
        "  if seed is None or seed == -1:valueSeed = inputSeed + i\n",
        "  image = generator.diffusion_enhance(\n",
        "    prompt,\n",
        "    negative,\n",
        "    scheduler_name=scheduler,\n",
        "    num_inference_steps=steps,\n",
        "    num_inference_steps_enhance=up_steps,\n",
        "    guidance_scale=CFG,\n",
        "    width=img_width,\n",
        "    height=img_height,\n",
        "    seed=valueSeed,\n",
        "    upscale_target=\"latent\",\n",
        "    interpolate_mode=\"bicubic\",\n",
        "    antialias=True,\n",
        "    # diffusion_enhance=True,\n",
        "    upscale_by=upscaling_ratio,\n",
        "    enhance_steps=enhance_steps,\n",
        "    denoising_strength=denoising_strength,\n",
        "    output_type=\"pil\",\n",
        "    decode_factor=0.15,\n",
        "    decode_factor_final=0.18215\n",
        "  )\n",
        "\n",
        "  # ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’å–å¾—\n",
        "  jst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))\n",
        "  #å‡ºåŠ›ã™ã‚‹ç”»åƒã®åå‰ã‚’ç”Ÿæˆã™ã‚‹\n",
        "  file_name = (jst_now.strftime(file_format)+ \"_\" + str(valueSeed))\n",
        "  image_name = file_name + f\".png\"\n",
        "\n",
        "  #ç”»åƒã‚’ä¿å­˜ã™ã‚‹\n",
        "  save_location = os.path.join(save_path, image_name)\n",
        "\n",
        "  #@markdown ***ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿***\n",
        "  save_metadata = True #@param {type: \"boolean\"}\n",
        "  if save_metadata:\n",
        "    metadata = PngInfo()\n",
        "    metadata.add_text(\"prompt\",(prompt))\n",
        "    metadata.add_text(\"negative\",(negative))\n",
        "    metadata.add_text(\"scheduler\",(scheduler))\n",
        "    metadata.add_text(\"steps\",(str(steps)))\n",
        "    metadata.add_text(\"CFG\",(str(CFG)))\n",
        "    metadata.add_text(\"width\",(str(img_width)))\n",
        "    metadata.add_text(\"height\",(str(img_height)))\n",
        "    metadata.add_text(\"seed\",str((valueSeed)))\n",
        "  if hires_fix:\n",
        "    metadata.add_text(\"upscaling ratio\",str((upscaling_ratio)))\n",
        "    metadata.add_text(\"up steps\",str((up_steps)))\n",
        "    metadata.add_text(\"denoising strength\",str((denoising_strength)))\n",
        "    image.save(save_location, pnginfo=metadata)\n",
        "  else:\n",
        "    image.save(save_location)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OIVx0EDv0Z7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ç”»åƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›\n",
        "\n",
        "import sys\n",
        "from PIL import Image\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "#@markdown **ä¿å­˜ã—ãŸç”»åƒã®ãƒ‘ã‚¹**\n",
        "file_dir = \"/content/drive/MyDrive/StableDiffusion/txt2img_output/test2/\"  #@param {type: \"string\"}\n",
        "file_name = \"20230710_170302_1067497271.png\" #@param {type: \"string\"}\n",
        "file_path = os.path.join(save_path, file_name)\n",
        "img = Image.open(file_path)\n",
        "\n",
        "print(\"Prompt: \",img.text[\"prompt\"])\n",
        "print(\"Negative Prompt: \",img.text[\"negative\"])\n",
        "print(\"Scheduler: \", img.text[\"scheduler\"])\n",
        "print(\"Steps: \",img.text[\"steps\"])\n",
        "print(\"CFG: \",img.text[\"CFG\"])\n",
        "print(\"Width: \",img.text[\"width\"])\n",
        "print(\"Height: \",img.text[\"height\"])\n",
        "print(\"Seed: \",img.text[\"seed\"])\n",
        "\n",
        "try:\n",
        "  print(\"Upscaling ratio; \",img.text[\"upscaling ratio\"])\n",
        "  print(\"Up steps: \",img.text[\"up steps\"])\n",
        "  print(\"Denoising strength: \",img.text[\"denoising strength\"])\n",
        "except:\n",
        "  print(\"Hires.fix was OFF.\")\n",
        "\n",
        "# %%writefile output.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}