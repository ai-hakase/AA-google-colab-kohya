{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koya-jp/AA-google-colab-kohya/blob/master/lama_cleaner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKe0DDAUgGBw",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79072017-8d31-4e84-885b-c73f28a92bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "ngrok public url: https://b3f5-34-132-168-114.ngrok-free.app.\n",
            "- Platform: Linux-\u001b[1;36m5.15\u001b[0m.\u001b[1;36m109\u001b[0m+-x86_64-with-glibc2.\u001b[1;36m35\u001b[0m\n",
            "- Python version: \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m\n",
            "- torch: \u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118\n",
            "- torchvision: \u001b[1;36m0.15\u001b[0m.\u001b[1;36m2\u001b[0m+cu118\n",
            "- Pillow: \u001b[1;36m9.4\u001b[0m.\u001b[1;36m0\u001b[0m\n",
            "- diffusers: \u001b[1;36m0.16\u001b[0m.\u001b[1;36m1\u001b[0m\n",
            "- transformers: \u001b[1;36m4.27\u001b[0m.\u001b[1;36m4\u001b[0m\n",
            "- opencv-python: \u001b[1;92m4.8.0.76\u001b[0m\n",
            "- xformers: N/A\n",
            "- accelerate: N/A\n",
            "- lama-cleaner: \u001b[1;36m1.2\u001b[0m.\u001b[1;36m3\u001b[0m\n",
            "- rembg: N/A\n",
            "- realesrgan: N/A\n",
            "- gfpgan: N/A\n",
            "\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2023-08-20 13:07:31.525798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: \"https://github.com/Sanster/models/releases/download/add_big_lama/big-lama.pt\" to /root/.cache/torch/hub/checkpoints/big-lama.pt\n",
            " 51% 99.1M/196M [00:00<00:00, 119MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-20T13:07:34+0000 lvl=warn msg=\"failed to open private leg\" id=8f5fdf928dcd privaddr=localhost:4242 err=\"dial tcp 127.0.0.1:4242: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 196M/196M [00:01<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-20T13:07:35+0000 lvl=warn msg=\"failed to open private leg\" id=5059477dc47e privaddr=localhost:4242 err=\"dial tcp 127.0.0.1:4242: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2023-08-20 13:07:35.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mdownload_model\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDownload model success, md5: e3aa4aaa15225a33ec84f9f4bc47e500\u001b[0m\n",
            "\u001b[32m2023-08-20 13:07:35.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.helper\u001b[0m:\u001b[36mload_jit_model\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mLoading model from: /root/.cache/torch/hub/checkpoints/big-lama.pt\u001b[0m\n",
            "Running on http://127.0.0.1:4242\n",
            " * Running on http://172.28.0.12:4242\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:40] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:40] \"GET /static/js/main.1fda6320.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:40] \"GET /static/css/main.ce986cc8.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"GET /model HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"GET /inputimage HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"GET /server_config HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"GET /is_desktop HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:42] \"GET /static/media/Inter-roman.var.ba4caefcdf5b36b438db.woff2 HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:44] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [20/Aug/2023 13:07:46] \"GET /model HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-20 13:07:56.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1280, 1280, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:07:56.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-08-20 13:07:56.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mRun crop strategy\u001b[0m\n",
            "\u001b[32m2023-08-20 13:07:56.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_crop_box\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mbox size: (156,235) crop size: (548, 626, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:07:56.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (552, 632, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:08:08.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 11243.360996246338ms\u001b[0m\n",
            "127.0.0.1 - - [20/Aug/2023 13:08:08] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-20 13:09:19.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1280, 1280, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:19.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:19.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mRun crop strategy\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:19.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_crop_box\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mbox size: (40,40) crop size: (432, 432, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:19.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (432, 432, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:24.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 5094.009876251221ms\u001b[0m\n",
            "127.0.0.1 - - [20/Aug/2023 13:09:24] \"POST /inpaint HTTP/1.1\" 200 -\n",
            "\u001b[32m2023-08-20 13:09:29.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mOrigin image shape: (1280, 1280, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:29.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mhd_strategy: Crop\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:29.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mRun crop strategy\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:29.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_crop_box\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mbox size: (33,40) crop size: (424, 432, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:29.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.model.base\u001b[0m:\u001b[36m_pad_forward\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mfinal forward pad size: (424, 432, 3)\u001b[0m\n",
            "\u001b[32m2023-08-20 13:09:34.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlama_cleaner.server\u001b[0m:\u001b[36mprocess\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mprocess time: 5581.252813339233ms\u001b[0m\n",
            "127.0.0.1 - - [20/Aug/2023 13:09:34] \"POST /inpaint HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Install package\n",
        "#@markdown # 1. Install package\n",
        "#@markdown Github Project: https://github.com/Sanster/lama-cleaner\n",
        "\n",
        "!pip3 install lama-cleaner pyngrok  >/dev/null 2>&1\n",
        "\n",
        "\n",
        "#@markdown # 2. Downloading model\n",
        "init_model = 'lama' #@param ['lama', 'sd1.5', 'paint_by_example']\n",
        "port = 4242\n",
        "\n",
        "#@markdown # !! Important Notes !!\n",
        "#@markdown Please stop this block after model download finish (seeing `running on http://0.0.0.0:4242/` in the log)\n",
        "\n",
        "\n",
        "# !lama-cleaner --host 0.0.0.0 --port $port --model $init_model\n",
        "#@markdown # 3. Setup ngrok\n",
        "#@markdown Get a free [ngrok](https://ngrok.com/) account and copy your authtoken [here](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "ngrok_authtoken = '' #@param {type: 'string'}\n",
        "\n",
        "!ngrok authtoken $ngrok_authtoken\n",
        "\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"ngrok public url: {public_url}.\")\n",
        "#@title 4. Start Lama Cleaner server\n",
        "#@markdown # 4. Start Lama Cleaner server\n",
        "#@markdown When you see `Running on http://0.0.0.0:4242/' in the log`, please open **ngrok public link**\n",
        "\n",
        "\n",
        "# !lama-cleaner --host 0.0.0.0 --port $port --model $init_model --device=cuda\n",
        "!lama-cleaner --host 0.0.0.0 --port $port --model $init_model --device=cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_vWkpLYi7wUG"
      },
      "outputs": [],
      "source": [
        "#@title 5. ランタイムの接続を解除して削除\n",
        "\n",
        "#@markdown # 5. ランタイムの接続を解除して削除\n",
        "\n",
        "# google.colabライブラリのインポート\n",
        "import google.colab\n",
        "\n",
        "# ランタイムの接続を解除して削除\n",
        "google.colab.runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}